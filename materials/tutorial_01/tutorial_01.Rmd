---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "c2bbf2d1aa462330a0a3a18e2c82f559", "grade": false, "grade_id": "cell-f1e1d845873036f4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# Tutorial 1: Introduction to Statistical Modelling and A/B Testing 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "179f0e3212588759d0b759ab9c6a1ca1", "grade": false, "grade_id": "cell-82d9926086d47a80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## Learning Objectives

After completing this week's worksheet and tutorial work, you will be able to:

1. Describe the goals of hypothesis testing, in particular difference in means tests related to A/B testing.
2. Give an example of a problem that requires A/B testing.
3. List methods used to test difference in means between two populations.
4. Interpret the results of hypothesis tests.
5. Explain the relation between type I and type II errors, power and sample size in 2-sample hypothesis testing.
6. Write a computer script to perform difference in means hypothesis testing and compute errors, power and p-values.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ae94d4ef67eb6acd2af686470d162fde', 'grade': False, 'grade_id': 'cell-a2a153352bc44a68', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing.
library(tidyverse)
library(infer)
library(broom)
library(cowplot)
library(binom)
source("tests_tutorial_01.R")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "da53f9ff6cb303688d14e07bb12b20b5", "grade": false, "grade_id": "cell-8a0e4c973d199032", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 1. Analysis of an A/B Testing Paper

In Worksheet 1, we reviewed key concepts of hypothesis tests to test the difference between two population means and discussed their relation to A/B testing. In this tutorial, you will review concepts related to the difference between two proportions, also seen before in STAT 201.

In this exercise, we will work with the paper ["Improving Library User Experience with A/B Testing: Principles and Process"](https://quod.lib.umich.edu/w/weave/12535642.0001.101?view=text;rgn=main) by Young (2014). This paper presents a case study where A/B testing is applied with different webpage designs. The primary aim is to compare user interactions to determine which one statistically improves the navigation experience by increasing the homepage click-through rate. The experiment was conducted using the web analytics software Google Analytics and Crazy Egg. The data from the paper can be found [here](https://scholarworks.montana.edu/xmlui/handle/1/3507).

The setup was done on the **Interact** category in the Montana State University's library webpage (more information can be found in the section *Step 1* in the paper). The experimental treatments (as explained and shown in *Step 4* in the paper) are the following: **Interact** (the control treatment), **Connect**, **Learn**, **Help**, and **Services**. The response variable is what we call the **click-through rate**, i.e., ratio of users that click on a specific link to the total number of users who view the page (a proportion that goes from 0 to 1).

We have already processed the data for you. Firstly, we load the Crazy Egg data from the web.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ff90740cbc64550585f723451ddcc836', 'grade': False, 'grade_id': 'cell-63b8c78459dc81f1', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
click_through <- 
    read_csv("data/click_through.csv") %>% 
    select(webpage, adjusted_clicks, target_clicks)

head(click_through)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "1afbf354ec7f668253fab92fa3ed8322", "grade": false, "grade_id": "cell-6c537789fff51e16", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.0**
<br>{points: 1}

The `adjusted_clicks` in the data frame `click_through` are the total clicks we will use to compute the click-through rate by treatment, where `target_clicks` are what we could define as **“successes”**. Compute the corresponding click-through rate by row by dividing `target_clicks` over `adjusted_clicks`. Add it as a new column in the data frame called `click_rate`. Then, reorder the experimental treatments (i.e., factor levels) in descending order by click-through rate.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'a6ee1e43545735cc4d8832fba17b9223', 'grade': False, 'grade_id': 'cell-84902e751c5c2aa3', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# click_through <- 
#     ... %>% 
#     mutate(click_rate = ...) %>% 
#     mutate(webpage = fct_reorder(..., desc(...)))

# your code here
click_through <- 
    click_through %>% 
    mutate(click_rate = target_clicks / adjusted_clicks) %>% 
    mutate(webpage = fct_reorder(webpage, desc(click_rate)))

click_through
levels(click_through$webpage)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '8bd204c8657f188bbb17df071a424fd4', 'grade': True, 'grade_id': 'cell-1fbf41f936a624e5', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.0()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "9a23e1a572aa06b6e90d81b1110a5254", "grade": false, "grade_id": "cell-2c6561413b54d3c4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.1**
<br>{points: 1}

The sampled click-through rates in the data frame `click_through` are estimates of population proportions. Hence, it is possible to obtain confidence intervals by relying on the Central Limit Theorem. Obtain the 95% confidence interval for each population click rate and store the lower and upper bounds in two new columns `click_through`: `lower_ci` and `upper_ci`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '22bdf8aaa0952552d6e02a9c533abd35', 'grade': False, 'grade_id': 'cell-a27d500f0b4c420e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# click_through <- 
#     click_through %>% 
#     ...(lower_ci = ...,
#            upper_ci = ...)

# your code here
click_through <- 
    click_through %>% 
    mutate(lower_ci = click_rate - qnorm(0.975) * sqrt(click_rate * (1 - click_rate) / adjusted_clicks),
           upper_ci = click_rate + qnorm(0.975) * sqrt(click_rate * (1 - click_rate) / adjusted_clicks))

click_through
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'de73496f4b32e4aae4f823efa6004fce', 'grade': True, 'grade_id': 'cell-c70d7b2c2aa8f378', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "3bf2ddb8d30777676b6c6938fcede1cf", "grade": false, "grade_id": "cell-a283262115be27b8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.2**
<br>{points: 1}

Let's create an effective visualization for the point estimate click_rate and the confidence intervals you obtained above. The `ggplot()` object's name shoud be `CIs_click_through_rates`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'c4bb81baf5333a8a2b7c1575acb578cd', 'grade': False, 'grade_id': 'cell-41b3cbbf1bc49165', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Plotting click-through rates as points with 95% confidence intervals.
# CIs_click_through_rates <- 
#   click_through %>% 
#   ggplot(aes(..., ...)) +
#   ...() +
#   geom_errorbar(aes(ymin = ..., ymax = ...), width = 0.1) +
#   theme(
#     text = element_text(size = 22),
#     plot.title = element_text(face = "bold"),
#     axis.title = element_text(face = "bold")
#   ) +
#   ggtitle(...) +
#   xlab(...) +
#   ylab(...)

# your code here
CIs_click_through_rates <- 
  click_through %>% 
  ggplot(aes(webpage, click_rate)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.1) +
  theme(
    text = element_text(size = 22),
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  ) +
  ggtitle("Click Rates with 95% CI") +
  xlab("Webpage") +
  ylab("Click Rate")

CIs_click_through_rates
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '0883ce716744c663a0e362e6b0c8081e', 'grade': True, 'grade_id': 'cell-062200921c05e43f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.2()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "33449c07bbe63d07e546561af8d26b57", "grade": false, "grade_id": "cell-bdcee83be072fc15", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.3**
<br>{points: 1}

Based on the findings in the plot `CIs_click_through_rates`, what can we statistically conclude from these confidence intervals?

**A.** We can see that treatment **Connect** has the largest click-through rate among the five treatments. It is statistically larger than the control treatment **Interact**.

**B.** We cannot state that treatment **Connect** is statistically larger than treatment **Services** since their confidence intervals overlap. However, we can state that these two treatments are statistically larger than the control treatment **Interact** and **Learn** given that their corresponding confidence intervals do not overlap.

*Assign your answer to an object called `answer1.3`. Your answer should be one of `"A"` or `"B"` surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'a5339c1f9b052ffdcd21ddc38abcf911', 'grade': False, 'grade_id': 'cell-314d32111def21c7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.3 <- 

# your code here
answer1.3 <- "B"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1f9761e8e63628577fa0547e416a0b01', 'grade': True, 'grade_id': 'cell-772a2e6ece3841c1', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.3()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "784d55b4af4e7b215f7416a7fa662d1e", "grade": false, "grade_id": "cell-690cc2c5994c6b30", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.4**
<br>{points: 1}

Recall that the click-through rates by treatment are proportions that go from 0 to 1. We want to compare whether the rate of a given treatment is larger than the rate corresponding to another one. Suppose we rely on the Central Limit Theorem and assume that our sample sizes are large enough. What is the specific analysis we need to perform?

**A.** One-sample $z$-test. 

**B.** One-sample $t$-test.

**C.** Two-sample $z$-test.

**D.** Two-sample $t$-test.

**E.** Two-way ANOVA.

*Assign your answer to an object called `answer1.4`. Your answer should be one of `"A"`, `"B"`, `"C"`, `"D"`, or `"E"` surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f94f3fe02b15720c43898cb34ce350b1', 'grade': False, 'grade_id': 'cell-4a49471cf41f1f67', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.4 <- 

# your code here
answer1.4 <- "C"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '07c1a359d16fc4826a2428cc2d9e33b5', 'grade': True, 'grade_id': 'cell-e76acfb5401abd0f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.4()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "beb1d09aca00dc6d8082573175e22dba", "grade": false, "grade_id": "cell-4b98156347b21735", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.5**
<br>{points: 1}

Let $p_A$ and $p_B$ be the click-through rates of two given treatments **A** and **B**, respectively. Suppose you want to assess whether the click-through rate of treatment **A** is larger than the one corresponding to treatment **B**. What is the set of hypotheses we are testing in this case?

**A.** $H_0: p_A = p_B$ vs. $H_1: p_A > p_B$

**B.** $H_0: p_A > p_B$ vs. $H_1: p_A < p_B$

**C.** $H_0: p_A = p_B$ vs. $H_1: p_A \neq p_B$

**D.** $H_0: p_A = p_B$ vs. $H_1: p_A < p_B$

*Assign your answer to an object called `answer1.5`. Your answer should be one of `"A"`, `"B"`, `"C"`, or `"D"` surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '9838b23ad0726b9ca95fe2d0f18a758e', 'grade': False, 'grade_id': 'cell-1b95fba9a44c72e9', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.5 <- 

# your code here
answer1.5 <- "A"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '21eb18a79459433ac57d892199c0892b', 'grade': True, 'grade_id': 'cell-6fa8808a79a82d33', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.5()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "9504e2343fdb8dd8ce2c7d7aa8eca4a1", "grade": false, "grade_id": "cell-e362f03b9d1a63a9", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.6**
<br>{points: 1}

Perform pairwise frequentist hypothesis test analyses to assess statistically significant differences between all the experimental treatments. This will require control for multiple comparisons. You can use the Bonferroni correction along with the function `pairwise.prop.test()`. Create an object named `pairwise_comparisons`. 

> **Heads-up:** Given the answer in **Question 1.6**, rows in `pairwise_comparisons` will correspond to treatment **A** and columns to treatment **B**.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5d39df1541a2c08da7542adf88a546f4', 'grade': False, 'grade_id': 'cell-b02a02d1ffacef41', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Assigning numbers of "successes" from data frame `click_through`
# successes <- click_through$...

# Assigning numbers of "trials" from data frame `click_through`
# trials <- click_through$...

# Putting labels on vector cells
# names(successes) <- click_through$webpage
# names(trials) <- click_through$webpage

# pairwise_comparisons <- pairwise.prop.test(x = ...,
#   n = ....,
#   p.adjust.method = ..., 
#   alternative = ...,
# )

# your code here

# Assigning numbers of "successes" from data frame `click_through`
successes <- click_through$target_clicks

# Assigning numbers of "trials" from data frame `click_through`
trials <- click_through$adjusted_clicks

# Putting labels on vector cells
names(successes) <- click_through$webpage
names(trials) <- click_through$webpage

pairwise_comparisons <- pairwise.prop.test(x = successes,
  n = trials,
  p.adjust.method = "bonferroni", 
  alternative = "two.sided",
)

pairwise_comparisons
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'aa3ba5eaa704119e6adc845fabe2e995', 'grade': True, 'grade_id': 'cell-19c172b9d9dea3d5', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.6()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f3181bde10df1c40d0ccb4ddfa2ae61c", "grade": false, "grade_id": "cell-e322c432c68a60e8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.7**
<br>{points: 1}

Based on your results in **Question 1.6**, using $\alpha = 0.05$, indicate what experimental treatments have a significantly larger click-through rate than the control **Interact**.

**A.** Connect.

**B.** Learn.

**C.** Help.

**D.** Services.

*Assign your answers to the object `answer1.7`. Your answer has to be a single string indicating the correct treatment labels **in alphabetical order** and surrounded by quotes (e.g., `"ABCD"` indicates you are selecting the four options).*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1c3fe5dce5d1c82c0250df6b5a87dfab', 'grade': False, 'grade_id': 'cell-8200f9e61e2c939b', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.7 <- 

# your code here
answer1.7 <- "AD"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5e9ac2b5d6d649e2f0c946737ee22d44', 'grade': True, 'grade_id': 'cell-8dcfca69365d2a13', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.7()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "de454a984c336bda59306f3c18cff039", "grade": false, "grade_id": "cell-b71652c72a001c12", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.8**
<br>{points: 1}

a) In one or two sentences, explain why a Bonferroni correction is needed to assess the significance of the pairwise the test performed in **Question 1.7**.

b) In one or two sentences, explain how to implement a Bonferroni correction in this case.
<!-- #endregion -->

<!-- #region deletable=false nbgrader={"cell_type": "markdown", "checksum": "4c75af71e710a06802c3b0f033538f1b", "grade": true, "grade_id": "cell-1f021334bf7674f3", "locked": false, "points": 1, "schema_version": 3, "solution": true, "task": false} -->
a) A Bonferroni correction is needed to assess the significance of the pairwise test because it controls the familywise error rate, which is the probability of making one or more false discoveries when performing multiple hypotheses tests.

b) To implement a Bonferroni correction in this case, I divide the desired significant level (e.g., 0.05) by the number of comparisons being made. For each individual test, I tried to compare its p-value against this adjusted Alpha to determine significance.
<!-- #endregion -->

```{r}

```
