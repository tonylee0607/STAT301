---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "43f2a4dab79483c826b08ed3405ba5fb", "grade": false, "grade_id": "cell-f1e1d845873036f4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# Worksheet 12: Binary or Discrete Counts Responses
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "338d963ee69f8faedab69db0f6d25bdb", "grade": false, "grade_id": "cell-82d9926086d47a80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Lecture and Tutorial Learning Goals:
After completing this week's lecture and tutorial work, you will be able to:

1. Describe the logistic regression estimation procedure (binary response variable), and Poisson regression estimation procedure (discrete counts as the response variable).
2. Discuss the relationship between linear regression and logistic and Poisson regression. Discuss the consequences of modeling data that is more suitable for logistic and Poisson regression models as a linear regression model.
3. Interpret the coefficients and $p$-values in the logistic and Poisson regression settings.
4. Write a computer script to perform logistic and Poisson regression and perform model diagnostics. Interpret and communicate the results from that computer script.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '087c055e30ff16cf47ce67825099376e', 'grade': False, 'grade_id': 'cell-a2a153352bc44a68', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing.
library(tidyverse)
library(repr)
library(digest)
library(infer)
library(gridExtra)
library(mlbench)
library(AER)
library(ISLR)
library(broom)
library(qqplotr)
library(performance)
library(see)
library(MASS)
library(glmbb)
library(cowplot)
source("tests_worksheet_12.R")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ea100688ea767bf0d06fb72cc460f9d8", "grade": false, "grade_id": "cell-82e529f0a9216400", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 1. Intro

In previous week, you explored the Multiple Linear Regression (MLR) as a way to model the mean of a numeric response variable, $Y$, given a set of covariate $\mathbf{X}$:

$$
E\left[Y\left|\mathbf{X}=\left(X_1,...,X_p\right)\right.\right] = \beta_0 + \beta_1X_1 + \ldots + \beta_pX_p
$$

However, in some situations, the MLR is not suitable. This week we are going to study two of those situations that commonly arises in practice:

- **in this worksheet**: the case of dichotomous response variables (e.g., yes/no, success/failure, win/lose, sick/not sick)  
- **in the tutorial**: the case of response variables representing counts (e.g., number of cases of a rare disease in Vancouver in a period of one year; the number of accidents in the Canada Highway in a period of one month).
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "bd123337ed378d509d674d57afb45d0e", "grade": false, "grade_id": "cell-9be71f65643c5906", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 1. Logistic Regression

Logistic Regressions are commonly used to model the probability of an event against a set of observed covariates.

As learned for Linear Regression, Logistic Regression can be used 

- to <font color=blue> **estimate  and  test** </font> the true relation between different type of variables and a **binary response**


- to <font color=blue> **predict** </font> the *probability* of a **binary response** (aka, classifier)

**For example**: we can use a logistic regression to

- compare the presence of a bacteria between groups taking a new drug and a placebo, respectively.
    - **response**: `present` or `not present`

- predict whether or not a customer will default on a loan given their income and demographic variables.
    - **response**: `default` or `not default`

- know how GPA, ACT score, and number of AP classes taken is associated with the probability of getting accepted into a particular university.
    - **response**: `accepted` or `not accepted`
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "a73772cca747b2773c4a701080994e04", "grade": false, "grade_id": "cell-f1fa818e59b35d73", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### The response variable:

In many applications, the response variable will not be a numeric vector in the dataset. In those cases, we need to create a new numerical response variable to fit a logistic model.
> the function in R to fit a logistic regression requires a numerical response and won't create it for us!

Mathematically, we have to construct a binary response $Y_i$ that represents the "proportion" of sucess (S) for a given event of interest: 

$$
Y_i =
\begin{cases}
1 \; \; \; \; \mbox{if the $i$th observation is S},\\
0 \; \; \; \; 	\mbox{otherwise.}
\end{cases}
$$

In the examples above, we would set:

- $Y_i = 1$ if the bacteria is present in the blood sample of the $i$th patient 


- $Y_i = 1$ if the $i$th customer defaulted on their loan


- $Y_i = 1$ if the $i$th student was accepted to a particular university


In statistics, we refer to each of cases as a **Bernoulli** trial with a $p_i$ probability of success, i.e., 

$$Y_i \sim \text{Bernoulli}(p_i)$$

where 

$$
E(Y_i) = p_i
$$
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "7630360deb8048c895326b3305a2de58", "grade": false, "grade_id": "cell-7aad649d27ed77eb", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
In this worksheet will focus on the dataset `Default` from [*An Introduction to Statistical Learning*](https://www.statlearning.com/) (James et al., 2013). This is a dataset of $n = 10,000$ observations with the following variables:

- `default`: a binary response indicating whether the customer defaulted on their debt (`Yes` or `No`).
- `student`: a binary input variable indicating whether the customer is a student (`Yes` or `No`).
- `balance`: a continuous input variable indicating the remaining average balance of the customer's credit card (after the monthly payment).
- `income`: a continuous input variable indicating the customer's income.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b96b0bf2d2dc5fe1c06048f774f68692', 'grade': False, 'grade_id': 'cell-be65b9244ff2e164', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
head(Default)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ee19e16c1430b3529cead015211b6e38", "grade": false, "grade_id": "cell-435c6ac14d8ae3f6", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.0**
<br>{points: 1}

We want to assess whether the response `default` is statistically associated to the input variables `student`, `balance`, and `income`. 

We need to construct a response $Y_i$ such that  $Y_i = 1$ if the $i$th customer is in default, and $0$ otherwise.

In the  `default` column, replace the levels `Yes` and `No` with the numerical values `1` and `0`, respectively.

**Note**: the response $y$ is an interger, *not* a factor, since we need R to interpret them as sample proportions.
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '744d7894a687b060c55550bcc554dcf4', 'grade': False, 'grade_id': 'cell-f583c10048ebd9d7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# default.df <- 
#     Default %>% 
#     ...(... = ...(..., 1, 0))

#head(default.df)

# your code here
default.df <- 
    Default %>% 
    mutate(default = if_else(default == "Yes", 1, 0))

head(default.df)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '4f4480133999e39828e209691ad87b1d', 'grade': True, 'grade_id': 'cell-80e35ff00a0d8926', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.0()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "b2be64412944109133d7ea2c01c1893b", "grade": false, "grade_id": "cell-52cf22804e4f9008", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### The conditional expectation 

We have seen before that a MLR

In this first exercise, we use a simple linear regression (SLR), as we have done before, to estimate the relation between `balance` and the response `default`.

As we previously recalled, a SLR will model: 

$$
E\left[Y_\texttt{default}|X_\texttt{balance}\right] = \beta_0 + \beta_1 X_\texttt{balance}
$$

However, since `default` is a binary variable we also know that its expectation equals the probability of default:

$$
E\left[Y_\texttt{default}|X_\texttt{balance}\right] = p_{\texttt{default}}
$$

> for simplicity, the subscript $i$ is omitted

Let's examine if there is a problem using a linear regression to model this conditional expectation. 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "dd379fb4c76ebda289ac9c49500544ed", "grade": false, "grade_id": "cell-ec0e34aef0968060", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.1**
<br>{points: 1}

Create a plot of the data (using `geom_point()`) along with the estimated regression line (using `geom_smooth()` with `method = "lm"`). Include proper axis labels. The `ggplot()` object's name will be `Default_SLR_plot`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b4c8ae8575b46169fd561af4abec1c3d', 'grade': False, 'grade_id': 'cell-beeb841f20cbe0b7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
options(repr.plot.width = 7, repr.plot.height = 5) # Adjust these numbers so the plot looks good in your desktop.

# Default_SLR_plot <- ...(...) +
#   ...(aes(..., ...)) +
#   ...(aes(..., ...), method = ..., se = FALSE) +
#   labs(y = ..., x = ...) +
#   ggtitle(...) +
#   ylim(-0.5, 1.5) +
#   theme(
#     text = element_text(size = 16.5),
#     plot.title = element_text(face = "bold"),
#     axis.title = element_text(face = "bold"),
#     legend.title = element_text(face = "bold")) +
#   scale_x_continuous(breaks = seq(0, 2500, 500))


# your code here
Default_SLR_plot <- ggplot(default.df) +
  geom_point(aes(balance, default)) +
  geom_smooth(aes(balance, default), method = "lm", se = FALSE) +
  labs(y = "Default", x = "Balance") +
  ggtitle("Simple linear Regression") +
  ylim(-0.5, 1.5) +
  theme(
    text = element_text(size = 16.5),
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold"),
    legend.title = element_text(face = "bold")) +
  scale_x_continuous(breaks = seq(0, 2500, 500))

Default_SLR_plot
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '517a6cdb14fdc0d88ff2ae2218bd6f20', 'grade': True, 'grade_id': 'cell-5f01635dd4cf6b6b', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "de8210a0fb82dc1a06e33e8cbb2325d5", "grade": false, "grade_id": "cell-a0c60c4720d6d478", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Class Discussion:** 

Do you see any problems with our model?  
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "bd5a09693ac165ea8c55941e878670aa", "grade": false, "grade_id": "cell-e2bdf22d86042c11", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Logistic Regression: an alternative to LR

The problem stems from using the *linear* model to estimate a probability! 

Mathematically, the linear component $\boldsymbol{X_i}^\top\boldsymbol{\beta}$ can take any value in $\mathbb{R}$ while $p_i$ has to be in [0, 1].

A natural way to solve this problem is to use a curve, instead of a line, with a range between $[0,1]$. One of such curves is the logistic curve:

$$E(Y_i|X_{\textit{i,balance}}) = p_i = \frac{e^{\beta_0 + \beta_1X_{\textit{i,balance}}}}{1+e^{\beta_0 + \beta_1X_{\textit{i,balance}}}}$$ 

**Note** that we are still using a linear component but not to directly model the conditional expectation. With some algebra, we can show that:

\begin{equation*}
\log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{i,\texttt{balance}}.
\end{equation*}

**Definition**: $p_i$ to $1 - p_i$ are also known as the **odds** and can be estimated by *number of sucesses* to *number of failures*

For example, among 7056 non-student customers, 206 defaulted on their debt. Thus, the odds that non-student customers default is 206 to 7056. 

The function $\log\left(\frac{p_i}{1 - p_i}\right)$ is called `logit`, and it is *logarithm of the odds*. 

Let's explore a bit this new function.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "c9d23e8446f38afabaefba22f7523158", "grade": false, "grade_id": "cell-33c529c35aa6d29d", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.2**
<br>{points: 1}

Let's see how the logistic curve looks like. In this exercise, you are going to plot the logistic curve to see how it behaves.

_Save the plot in an object named `logistic_curve`._
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'a9065d3e33d8b03430b7e82093470e67', 'grade': False, 'grade_id': 'cell-ebd9f096f835b1b0', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# logistic_curve <-
#     tibble(z = seq(-10,10,0.01),
#            logistic_z = ...) %>% 
#     ggplot(aes(z, ...)) + 
#     geom_line() +
#     geom_hline(yintercept = 1, lty=2) + 
#     geom_hline(yintercept = 0, lty=2) +
#     theme(text = element_text(size = 20)) + 
#     ggtitle("Logistic curve")

# your code here
logistic_curve <-
    tibble(z = seq(-10,10,0.01),
           logistic_z = exp(z)/(1+exp(z))) %>% 
    ggplot(aes(z, logistic_z)) + 
    geom_line() +
    geom_hline(yintercept = 1, lty=2) + 
    geom_hline(yintercept = 0, lty=2) +
    theme(text = element_text(size = 20)) +
    ggtitle("Logistic curve")
logistic_curve
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ecf65b1c668b9efa77e328b0933067be', 'grade': True, 'grade_id': 'cell-7728e71dc711badb', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.2()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "71579f9316adb6afbf36f0e331550237", "grade": false, "grade_id": "cell-1f6a141622c13896", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.3: Understanding the odds**
<br>{points: 1}

Vancouver Canucks is playing against Calgary Flames in the Final of NHL. The match will be at Rogers' arena, Canucks home. It is expected that out of 18,910 seats in the arena, 13700 seats will be occupied by Canucks fans. During the match, prizes are randomly distributed among the seats. What are the odds that a Canucks fan wins a given prize? 

Assign your answer to an object named `answer1.3`.
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '836ce27b9d3fa4140dea20c3ceb8bb8f', 'grade': False, 'grade_id': 'cell-ee8b9ad3125f8346', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
#answer1.3 <- ...

# your code here
answer1.3 <- 13700/(18910 - 13700)

answer1.3
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '15f77319d1592683114eb33627f52723', 'grade': True, 'grade_id': 'cell-85f66b5726146ab1', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.3()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "636357e23eb20f894aa0814c62f33a38", "grade": false, "grade_id": "cell-8a7c7401c453d69c", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.4:**
<br>{points: 1}

Let us plot the predictions of the binary logistic regression model on top of `Default_SLR_plot`. Use `geom_smooth()` with `method = "glm"` and `method.args = c(family = binomial)`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'c6c6408783c4d50cd85a3d3497d72a2b', 'grade': False, 'grade_id': 'cell-47acd27ded854e48', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Default_SLR_plot <- 
#     Default_SLR_plot +
#     ...(aes(..., ...),
#         method = ...,
#         method.args = ..., 
#         se = FALSE, color = "red") +
#     ylim(-0.5,1.5)  +
#     ggtitle("Simple Linear Regression and Binary Logistic Regression")

# your code here
# Default_SLR_plot <- 
    Default_SLR_plot +
    geom_smooth(aes(balance, default),
        method = "glm",
        method.args = c(family = binomial), 
        se = FALSE, color = "red") +
    ylim(-0.5,1.5)  +
    ggtitle("Simple Linear Regression and Binary Logistic Regression")


Default_SLR_plot
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'e2abe04eb35bee83f8eb82ef34ad35bb', 'grade': True, 'grade_id': 'cell-4989d973853e512d', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.4()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "55d066dcc3c785ec147c6536046c0507", "grade": false, "grade_id": "cell-a628cff07e7aa9ce", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
Much better, isn't it? 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "01ce4ec9ae2e693f80c6850ff13ff62e", "grade": false, "grade_id": "cell-ed0a86b15f54a046", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### The model

Let's review our model!

The response: 

$$
Y_i =
\begin{cases}
1 \; \; \; \; \mbox{if the $i$th observation is a success},\\
0 \; \; \; \; 	\mbox{otherwise}
\end{cases}
$$

can only take the values $0$ or $1$. 

The conditional expected value of this variable is the probability that $Y_i$ takes on the value of $1$, or probability of success, denoted as $p_i$. Hence:

$$\left.Y_i\right|\mathbf{X}_{i} \sim \text{Bernoulli}(p_i).$$

The <font color = "blue"> **logistic regression** </font> models the probability $p_i$ given the information of a set of covariates but *not* directly as a linear function of them. Instead, it re-expresses $p_i$ on an unrestricted scale, called the <font color = "blue"> **log-odds** </font>:

$$
\mbox{logit}(p_i) = \log \bigg( \frac{p_i}{1 - p_i}\bigg) = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_{q} X_{iq},
$$

> the logarithm of the odds is the logarithm of the ratio of the probability of a sucess to the probability of a failure of an event

Or equivalently

$$
p_i = \frac{\exp\big[\beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_{q} X_{iq}\big]}{1 + \exp\big[\beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_{q} X_{iq}\big]}.
$$

**In our example**

$$
\mbox{logit}(p_{i,\texttt{default}}) = \log \bigg( \frac{p_{i,\texttt{default}}}{1 - p_{i,\texttt{default}}}\bigg) = \beta_0 + \beta_1 X_{i,\texttt{balance}}
$$

or equivalently

$$
p_{i,\texttt{default}} = \frac{e^{\beta_0 + \beta_1 X_{i,\texttt{balance}}}}{1 + e^{\beta_0 + \beta_1 X_{i,\texttt{balance}}}}.
$$

In this example, the *odds* are interpreted as how likely the $i$th customer is to be in default compared to how unlikely it is, at a fixed value of their balance. 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "478bbd3214d6111adc5062fe76be7d3b", "grade": false, "grade_id": "cell-f7510c5644481477", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### 1.1 Estimation

The question now is, how do we estimate the coefficients $\beta_j$'s? 

So far, in the case of linear regression, we have been using the Least Square Estimators. However, due to type of response of the logistic model this objective function is no longer appropriate.

A common method to estimate a logistic regression (and many other models) is a method called **Maximum Likelihood Estimation**. Details of MLE are outside the scope of this course but we will still implement it using R! 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f61f4627cfa5bf01614da8ce6769a34c", "grade": false, "grade_id": "cell-9e11a13acd8b9ad1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->

**Interpretation**

As before, the interpretation of the coefficients will depend on the type of input variable. 

Let's start by looking at a model with only 1 categorical covariate. For example, being or not being a student.

We know that in this case, `R` will create a dummy variable $X$ to include in the model. But how do we interpret its coefficient??

> for LR, the intercept was the mean of the response of the reference group (and the *estimate* was the *sample* mean)

> for LR, the "slope" was the *difference* between the mean of the response of the treatment group vs that of the reference group (and the *estimate* was the difference of *sample* means)

But for LR, we modeled directly the expected value of the response. We now need to adjust the interpretations to changes in *log-odds*!!

- Intercept: $\hat{\beta}_0$ represents the log-odds of the reference group (e.g., non-students)

- Slope: $\hat{\beta}_1$ represents the difference in log-odds between the treatment and the reference group (e.g., students vs. non-students)

Since log-odds are difficult to interpret, it is common to also interpret the exponentiated version of the coefficients:

- Intercept: $e^{\hat{\beta}_0}$ represents the odds of the reference group, i.e., proportion of success relative to proportion of failures in the sample 

- Slope: $e^{\hat{\beta}_1}$ represents the *odds ratio*, i.e., ratio between the odds of the treatment vs the odds of the reference group

*Run the cell below to compute these quantities. Read and follow calculations*
<!-- #endregion -->

```{r}
default.df %>% dplyr::select(default, student) %>% 
    group_by(default, student)%>%
    summarise(n=n(), .groups = 'drop')
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '81016176e41809c5ea79cda11899053e', 'grade': False, 'grade_id': 'cell-30b101cea83cb90f', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# b0 = \hat{beta}_0
tot_studentNo <- 6850 + 206
# probability of default if non-student
# note that the same is true for #default1_studentNo/#default0_studentNo
p_studentNo <- 206/tot_studentNo
b0 <- log(p_studentNo/(1-p_studentNo))

# b1 = \hat{beta}_1
tot_studentYes <- 2817 + 127
# probability of default if student
p_studentYes <- 127/tot_studentYes
# log odds of students vs. log odds of non-students
b1 <- log(p_studentYes/(1-p_studentYes)) - b0

print("log-odds for non-students (b0) and for students")
c(b0,log(p_studentYes/(1-p_studentYes))) %>% round(3)


print("odds for non-students (exp(b0)) and for students")
c(exp(b0),(p_studentYes/(1-p_studentYes))) %>% round(3)


print("odds ratio (exp(b1))")
c(exp(b1), 
  (p_studentYes/(1-p_studentYes))/(p_studentNo/(1-p_studentNo)))  %>% 
  round(3)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "5e2a17e94044cbaf3b4874c5b156e9f7", "grade": false, "grade_id": "cell-a3e8e0c543a5d4ea", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.5:**
<br>{points: 1}

In order to fit the model, we can use the function `glm()` and its argument `family = binomial` (required to specify the binary nature of the response). 

Let us use the function `glm()` to estimate a binary logistic regression. Using `default.df`, we will fit a binary logistic model with `default` as the response and `student` as input variable.
    
Store the model in an object named `Default_binary_log_student`. The `glm()` parameters are analogous to `lm()` (`formula` and `data`) with the addition of `family = binomial` for this specific model. 
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '73c8f88203971ea30b4fdffd5a7bcd8e', 'grade': False, 'grade_id': 'cell-8ac0e64c9daf4ffc', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Default_binary_log_student <- 
#   ...(
#        formula = ...,
#        data = ...,
#        family = ...)


# your code here
Default_binary_log_student <- 
  glm(
       formula = default ~ student,
       data = default.df,
       family = ...)

summary(Default_binary_log_student)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '9f286a3c5b2ad6c51b25dc02ee65f1ac', 'grade': True, 'grade_id': 'cell-debd081e1606b49a', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.5()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "04b74bd9ec3596fb96c3024af41b5e06", "grade": false, "grade_id": "cell-de489b368280eba8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
Note that you can also use the function `tidy()` to obtain a summary table of results.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ac8e6a193d25e0a49d57dbfa9ae4c707', 'grade': False, 'grade_id': 'cell-68c04287f7d21da3', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
#Run this cell to get a tidy summary table

Default_binary_log_student_results  <-
    tidy(Default_binary_log_student) %>% 
    mutate(exp.estimate = exp(estimate)) %>% 
    mutate_if(is.numeric, round, 3)

Default_binary_log_student_results 
```

**Note**: you can also get the exponentiated coefficients with the argument `exponentiate = TRUE` in `tidy()`. Note that the SEs are adjusted as well so this would be a better approach!

```{r}
tidy(Default_binary_log_student, exponentiate = TRUE)%>% 
    mutate_if(is.numeric, round, 3)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "d138132eae20c50ea25285328a5e0a2f", "grade": false, "grade_id": "cell-6665a0ff5a730bdf", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.6**
<br>{points: 1}

Considering the `Default_binary_log_student_results` tibble, what is the correct interpretation of the  $\hat{\beta}_\textit{student}$?

**A.** The odds of default are $49.9\%$ higher for non-student custormers compared to student customers.

**B.** The odds of default are $49.9\%$ higher for student custormers compared to non-student customers.

**C.** The odds of default are $40.5\%$ higher for non-student custormers compared to student customers.

**D.** The odds of default are $40.5\%$ higher for student custormers compared to non-student customers.

*Assign your answer to the object `answer1.6` (character type surrounded by quotes).*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5061c90ecf4e6a196e542aea2f516667', 'grade': False, 'grade_id': 'cell-9d862eda2ad912b4', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.6 <- ...

# your code here
answer1.6 <- "B"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '48a900d29872eb46d146064466276e40', 'grade': True, 'grade_id': 'cell-454d0bf3ba416081', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.6()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "de9f91a15d444e3d56b341b6d427ec1b", "grade": false, "grade_id": "cell-4bf8d13d2489425d", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Multiple covariates

And the interpretation extends to the case of more covariates of different types

- $\hat{\beta}_1$ gives the changes in log odds per one-unit increase in X, 
    - or equivalently it multiplies the odds by $e^{\hat{\beta}_1}$
    
> **Note**: because the relationship between $p_i$ and $X_i$ is not a straight line, $\hat{\beta}_1$ does not correspond to the change in $p_i$ associated with a one-unit change in $X_i$. But regardless,
if $\hat{\beta}_1$ is positive then increasing $X_i$ will be associated with increasing $p_i$ and visceversa.

> **Note**: when the odds decreases, i.e., negative change in log-odds, it is easier to interpret $1/e^{\hat{\beta}_1}$. That is, to redefine odds= #failures/#successes
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "0804ff676094f93274dcd376ffabea74", "grade": false, "grade_id": "cell-148b1dc1b2667581", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.7:**
<br>{points: 1}

In order to fit the model, we can use the function `glm()` and its argument `family = binomial` (required to specify the binary nature of the response). 

Let us use the function `glm()` to estimate a binary logistic regression. Using `default.df`, we will fit a binary logistic model with `default` as the response and `student`, `balance`, and `income` as input variables.
    
Store the model in an object named `Default_binary_log_model`. The `glm()` parameters are analogous to `lm()` (`formula` and `data`) with the addition of `family = binomial` for this specific model. 
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '7fc03bcc53654a144e281aa0f3c33b70', 'grade': False, 'grade_id': 'cell-7097573be6a38bf2', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Default_binary_log_model <- 
#   ...(
#        ...,
#        ...,
#        ...)

#tidy(Default_binary_log_model) %>% 
#         mutate_if(is.numeric, round, 3)
#tidy(Default_binary_log_model, exponentiate = TRUE) %>% 
#         mutate_if(is.numeric, round, 3)

# your code here
Default_binary_log_model <- 
  glm(
       default ~ student + balance + income,
       data = default.df,
       family = binomial)

tidy(Default_binary_log_model) %>% 
    mutate_if(is.numeric, round, 3)
tidy(Default_binary_log_model, exponentiate = TRUE) %>% 
    mutate_if(is.numeric, round, 3)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b186bf9f116ab25d76f66c78304a40df', 'grade': True, 'grade_id': 'cell-a0e923b260f01656', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.7()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "2054c9f83c1326c5421a8da34c840a94", "grade": false, "grade_id": "cell-5fe352592ed23811", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.8**
<br>{points: 1}

Considering the `Default_binary_log_model_results` tibble, what is the correct interpretation of the  $\hat{\beta}_\textit{student}$?

**A.** Since, $1 / 0.524 = 1.908$, we estimate that the odds of non-default are $90.8\%$ higher for non-student custormers compared to student customers, while keeping the rest of the input variables constant.

**B.** Since, $1 / 0.524 = 1.908$, we estimate that the odds of default are $90.8\%$ higher for non-student custormers compared to student customers, while keeping the rest of the input variables constant.

**C.** Since, $1 / 0.524 = 1.908$, we estimate that the odds of non-default are $90.8\%$ higher for student custormers compared to non-student customers, while keeping the rest of the input variables constant.

**D.** Since, $1 / 0.524 = 1.908$, we estimate that the odds of default are $90.8\%$ higher for student custormers compared to non-student customers, while keeping the rest of the input variables constant.

*Assign your answer to the object `answer1.8` (character type surrounded by quotes).*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'a52e8dcb232f6c3226e33b6217364aed', 'grade': False, 'grade_id': 'cell-11677807d101b133', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.8 <- ...

# your code here
answer1.8 <- "C"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f8b8b2dbc78416121455ee492281fa03', 'grade': True, 'grade_id': 'cell-30f034478ea08799', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.8()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "66633e2f35bab1d5f2a72e59e1348e6d", "grade": false, "grade_id": "cell-7960f6f613499491", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.9**
<br>{points: 1}

What is the correct interpretation of the regression equation's estimated slope for `balance`?

**A.** A $\$1$ increase in `balance`, is associated with a $0.6\%$ increase in the odds of a customer to be in default, while keeping the rest of the input variables constant. 

**B.** A $\$1$ increase in `balance`, is associated with a $0.6\%$ increase in the odds of a customer to not be in default, while keeping the rest of the input variables constant.  

**C.** A $\$1$ increase in `balance`, is associated with a $0.6\%$ increase in the odds of a student customer to be in default, while keeping the rest of the input variables constant.  

**D.** A $\$1$ increase in `balance`, is associated with a $0.6\%$ increase in the odds of a non-student customer to be in default, while keeping the rest of the input variables constant.

*Assign your answer to the object `answer1.9` (character type surrounded by quotes).*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '19623ffd8cd12291e421b7f8a0cc12cb', 'grade': False, 'grade_id': 'cell-7441e6aa1307023f', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.9 <- ...

# your code here
answer1.9 <- "A"

```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '4809d604ee9b9b23b53ce01c29a0e108', 'grade': True, 'grade_id': 'cell-347ad929fad50479', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.9()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "a7dd6ecd9ec8878252d59647e82b6d6a", "grade": false, "grade_id": "cell-8357d4c87f849b10", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### 1.2 Inference

We can use this estimated model to make inference about the population parameters, i.e., we can determine whether an input variable is statistically associated with the logarithm of the odds through hypothesis testing for the parameters $\beta_j$. 

To do that, we need additional information about the estimators of the  regression coefficients, $\hat{\beta}_j$. In particular, we need their sampling distribution and corresponding standard errors, $\mbox{SE}\left(\hat{\beta}_j\right)$. 

**Theoretical test**:

To test the hypotheses
\begin{gather*}
H_0: \beta_j = 0\\
H_a: \beta_j \neq 0.
\end{gather*}

you can use the Wald statistic $z_j$

$$z_j = \frac{\hat{\beta}_j}{\mbox{SE}\left(\hat{\beta}_j\right)}$$

which under $H_0$ has an approximately standard normal distribution provided the sample size $n$ is large enough.

> this statistic is analogous to the $t$-value used in LR. 

Furthermore, given a specified level of confidence, we can construct approximate $(1 - \alpha) \times 100\%$ confidence intervals for the corresponding true value of $\beta_j$:

$$\hat{\beta}_j \pm z_{\alpha/2}\mbox{SE}\left(\hat{\beta}_j\right),$$

where $z_{\alpha/2}$ is the upper $\alpha/2$ quantile of the standard normal distribution.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "d2bcf7253b1378ab67cead3e877bb314", "grade": false, "grade_id": "cell-c18026a5fd84fca7", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.10: Inference**
<br>{points: 1}

Report the estimated coefficients, their standard errors, and corresponding $p$-values by calling `tidy()` on `Default_binary_log_model`. Include the corresponding asymptotic 95% confidence intervals. 

_Store the results in the variable `Default_binary_log_model_results`._
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b72573f0960e69b8e55c9ac8b373b79a', 'grade': False, 'grade_id': 'cell-ad37611aa165ca7a', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Default_binary_log_model_results <- 
#   ...(..., conf.int = TRUE) 

# your code here
Default_binary_log_model_results <- 
  tidy(Default_binary_log_model, conf.int = TRUE) 

Default_binary_log_model_results
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '92a3208529cd7c7a0d2ccc4fdaf2e45f', 'grade': True, 'grade_id': 'cell-38f7c2eea95906c9', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.10()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "34f7ea6dd9dba6baa48fb9550c013c93", "grade": false, "grade_id": "cell-82749136a082e937", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.11: Inference**
<br>{points: 1}

Use `tidy()` to  the estimated effect each of the variables has on the **odds** to the `Default_binary_log_model_results` tibble. Make sure to also include the confidence interval for these effects.
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1c4cbbede9240f2a0d3392e18fb5cf5e', 'grade': False, 'grade_id': 'cell-366329ae6e91a284', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Default_binary_odds_model_results <- 
#   ... %>%
#   mutate_if(is.numeric, round, 6)

# your code here
Default_binary_odds_model_results <- 
  tidy(Default_binary_log_model, conf.int = TRUE, exponentiate = TRUE) %>%
  mutate_if(is.numeric, round, 6)

Default_binary_odds_model_results
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '505b346f8721786c9ec10aa064641509', 'grade': True, 'grade_id': 'cell-b905bb95b0e06997', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.11()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f95edcda4f00e0f3fc5b6b692dfed17f", "grade": false, "grade_id": "cell-d9141f6447689b01", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.12**
<br>{points: 1}

Using a **significance level $\alpha = 0.05$**, which inputs are statistically associated to the probability of default in `Default_binary_log_model_results`?

**A.** The categorical input `student`.

**B.** The continuous input `balance`.

**C.** The continuous input `income`.

*Assign your answers to the object `answer1.12`. Your answers have to be included in a single string indicating the correct options **in alphabetical order** and surrounded by quotes (e.g., `"ABC"` indicates you are selecting the three options).*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1921a0f4b26d34ce61fe714041abb812', 'grade': False, 'grade_id': 'cell-822cb96c53313b4e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.12 <- 

# your code here
answer1.12 <- "AB"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '535f53f696cf6606d87d1581eff0df56', 'grade': True, 'grade_id': 'cell-a04e784c42d742dc', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.12()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "2ee271aada5209b247a9c9de38590baf", "grade": false, "grade_id": "cell-a1792c454ca79341", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### 1.3 Prediction

Besides inference, we can use an estimated logistic regression model to predict the probability of success. 

\begin{gather*} 
\log \bigg( \frac{\hat{p}_i}{1 - \hat{p}_i}\bigg) = \hat{\beta}_0 +\hat{\beta}_1 x_{i1} + \ldots + \hat{\beta}_p x_{iq} \\
\end{gather*}

where lower letters $x$ were used to denote a particular observed value for the $i$th experimental unit.

**For example:**

Suppose we want to predict the odds of a student who has a credit card balance of \\$2200 and an income of \\$35000 to be in default relative to not being in default.

Mathematically (omitting $i$th for simplicity), our predicted log odds will be 

\begin{gather*} 
\log \bigg( \frac{\hat{p}_\texttt{default}}{1 - \hat{p}_\texttt{default}}\bigg) = \underbrace{-10.869045}_{\hat{\beta}_0} - \underbrace{0.646776}_{\hat{\beta}_1} \times (1) + \underbrace{0.005737}_{\hat{\beta}_2} \times (2200) + \underbrace{0.000003}_{\hat{\beta}_2} \times (35000)= 1.21 \\
\end{gather*}

Next, by taking the exponential on both sides of the equation, we obtain our predicted *odds*: 

$$
\frac{\hat{p}_\texttt{default}}{1 - \hat{p}_\texttt{default}} = e^{1.21} = 3.36.
$$

Finally, solving the above for $\hat{p}_\texttt{default}$, we obtain our predicted probability of default

$$
\hat{p}_\texttt{default} = 3.36/4.36 = 0.7706
$$
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f4143eda53199547d5343caf421d55c4", "grade": false, "grade_id": "cell-cfbfd19ea63f8152", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.13**
<br>{points: 1}

Using `predict` and `Default_binary_log_model`, obtain the odds prediction above.

> **Hint:** Check the argument `type` when coding this prediction.

*Assign your answer to the object `answer1.13`. Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f7aaf749f2d98f24a73849cc5ef62f72', 'grade': False, 'grade_id': 'cell-23f0d706c79c9f1c', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.13 <- exp(...(...,
#   tibble(..., ..., ...),
#   type = ...))

# your code here
answer1.13 <- exp(predict(Default_binary_log_model,
  tibble(student = "Yes", balance = 2200, income = 35000),
  type = "link"))

answer1.13
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'dfa62c02c59648c0455073c973242fe7', 'grade': True, 'grade_id': 'cell-e8a22ef2e4ac8fe6', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.13()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "e4e818ff3ea708b153256ef71333c4e8", "grade": false, "grade_id": "cell-f84da54cd4da6b01", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.14**
<br>{points: 1}

We can also predict probabilities for classification purposes, i.e., whether the customer will default or not. Using the function `predict()` with the object `Default_binary_log_model`, obtain the estimated probability for a customer being in default. This customer is a `student` who has a credit card `balance` of `2200` with an income of `35000`.

> **Hint:** Check the argument `type` when coding this prediction.

*Assign your answer to the object `answer1.14`. Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '4ce8362e7211329066581c675826eb3d', 'grade': False, 'grade_id': 'cell-ee0c66cf674510cc', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.14 <- 
#   ...(...,
#     tibble(..., ..., ...),
#     type = ...)

# your code here
answer1.14 <- 
  predict(Default_binary_log_model,
    tibble(student = "Yes", balance = 2200, income = 35000),
    type = "response")


answer1.14
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '6c96e6a22f12b6ca559b6781d603b09f', 'grade': True, 'grade_id': 'cell-03c8e23b29226318', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.14()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "423fa69640684569da769ed243209f7a", "grade": false, "grade_id": "cell-5d4b54303734b4c1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Overdispersion**

The variance of a binary response variable is a function of the mean: $p(1-p)$. What this means is that, the estimate of the mean also provides an estimate of the variance of the response. 

Since the logistic regression is built assuming that the response is *Bernoulli*, the estimated $\hat{p}$ conditions the estimated variance of the response to be $\hat{p}(1-\hat{p})$.  

Unfortunately, in real applications, even in situation where the model seems to be estimating the mean well, the variability of the data is not quite compatible with the model's assumed variance.

> this misspecification in the variance affects the SE of the coefficients, not their estimates.

A way around this problem is to estimate a dispersion parameter, usually called $\phi$, to correct the standard error of our estimators. An easy implementation is to change the `family` argument to a `quasibinomial`. Let's see an example.  
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '8add326ccea85b3907d01445cdf32c31', 'grade': False, 'grade_id': 'cell-5d6361d8c9695383', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
summary(glm(
    formula = default ~ student + balance + income,
    data = Default,
    family = quasibinomial))
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "030f81bd873d8a52465cf2f85955b749", "grade": false, "grade_id": "cell-69697cc0a73122ef", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Note** that the estimates haven't changed but the SE were adjusted to account for some overdispersion in the data.

### 1.4 Conclusions

- The (conditional) expectation of a binary response is the probability of success.

- A LR can not be used to model the conditional expectation of a binary response since its range extends beyond the interval $[0,1]$

- Instead, one can model a function of the conditional probability. A common choice in logistic regression is to use the *logit* function (logarithm of odds)

- The interpretation of the coefficients depends on the type of variables and the form of the model:

The raw coefficients are interpreted as:

- log-odds of a reference group
- difference of log-odds of a treatment vs a control group
- changes in log-odds per unit change in the input
    
The exponentiated coefficients are interpreted as:
- odds of a reference group
- odds ratio of a treatment vs a control group
- multiplicative changes in odds per unit change in the input
    
- The estimated logistic model can be used to make inference using the Wald's test

- The estimated logistic model can be used to make predictions
    - the probability of success
    - the odds of success relative to failure
<!-- #endregion -->
