---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "842fedd16ebb5ee8bf1beee6610a28b3", "grade": false, "grade_id": "cell-f1e1d845873036f4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# Worksheet 5: Model Asssumptions and Causality
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "e7042787fe9861997a04e4663207d6ba", "grade": false, "grade_id": "cell-82d9926086d47a80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Lecture and Tutorial Learning Goals:
After completing this week's lecture and tutorial work, you will be able to:

1. Describe heteroscedasticity and the problem it presents to generative modeling.
2. Write a computer script to assess whether heteroscedasticity in a given data set, and if so, use practical solutions to manage it.
3. Describe colinearity and the problem it presents to generative modeling.
4. Write a computer script to assess whether collinearity exists between input variables in a given data set, and if so, use practical solutions to manage it.
5. Discuss why a data scientist may need to consult a domain expert when examining model assumptions.
6. Give an example of a real problem that aims to test a causal relationship between variables.
7. Give an example of a real problem the model can only establish an association between the response and the input variables.
8. Discuss how the desired goal of generative modelling is usually to make causal claims however we cannot often/easily do so (e.g., in particular in the context of observational studies).
9. Discuss the role of confounders in causal inference.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b3f67dde851be371b452a3d83c399715', 'grade': False, 'grade_id': 'cell-a2a153352bc44a68', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing.
library(tidyverse)
library(repr)
library(infer)
library(cowplot)
library(broom)
library(faux)
source("tests_worksheet_05.R")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "5e465c8d7d447a0c0e2f8ae44aea6854", "grade": false, "grade_id": "cell-a7afce7a95d0bf98", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# PART I
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "350e03c690b2e3fee0d6bb1ca60fe5aa", "grade": false, "grade_id": "cell-fa599c4dd2ab0c31", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## Model Assumptions

When we analyze a dataset to respond to a question of interest, we make several assumptions. However, in practice, many of these assumptions may not be true posing many problems in our analysis. The most common problems that we may encounter are:

1. the relation between the response and the input variable(s) is not linear
2. error terms are correlated (not independent as we assumed)
3. error terms do not have a common variance (not identically distributed as we assumed)
4. error terms are not Normally distributed (not a strong assumption but convenient)
5. (some) input variables are correlated

"In practice, identifying and overcoming these problems is as much an
art as a science" (from ISL, Section 3.3.3). 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "e8f99a564d87c7f7b2bc3fbb6d937471", "grade": false, "grade_id": "cell-382d4cff30ea6f88", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 1. Warm Up Questions
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "6c411b1409ad7655b3c9291f1edc8de2", "grade": false, "grade_id": "cell-e09a0361f4541bf3", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.1**
<br>{points: 1}

True or false?

The results of the test of hypotheses given by `lm()` are only valid if we assume that the errors in the linear regression model are (exactly) Normally distributed.

*Assign your answer to an object called `answer1.1`. Your answer should be either "true" or "false", surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '72e1f9812d2c8ae9f6befa18ba62bf9e', 'grade': False, 'grade_id': 'cell-44f5390242e66448', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.1 <- ...

# your code here
answer1.1 <- "false"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ef677d01b8a28c62ca8865971fc84219', 'grade': True, 'grade_id': 'cell-8fed7ee78a3eb713', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "5c5f63046264e5e2d3910c8f1f018221", "grade": false, "grade_id": "cell-0cd72706949e2df2", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.2**
<br>{points: 1}

True or false?

In a linear regression, multicollinearity refers to the correlation between each input variable with the response variable.

*Assign your answer to an object called `answer1.2`. Your answer should be either "true" or "false", surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '7e068c65b003a4402a11e3835d9485c2', 'grade': False, 'grade_id': 'cell-dcf5e346ae4d23b2', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.2 <- ...

# your code here
answer1.2 <- "false"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '38c9bfbb9000f54bf51e4ca3098d2c69', 'grade': True, 'grade_id': 'cell-9c7fa20462d3583a', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.2()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "2245140e9709d6efa6f5a9f842dc7dd5", "grade": false, "grade_id": "cell-b081691974727e18", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.3**
<br>{points: 1}

True or false?

In the presence of multicollinearity in a multiple linear regression (MLR), it can be difficult to determine how collinear variables are separately associated with the response.

*Assign your answer to an object called `answer1.3`. Your answer should be either "true" or "false", surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ae93575c0096dac56dbc38fc1630d809', 'grade': False, 'grade_id': 'cell-2e7e71146f6c4cf0', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.3 <- ...

# your code here
answer1.3 <- "true"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '9e0b37b9acc3eb4033227043a72b6c3d', 'grade': True, 'grade_id': 'cell-3e42935abf1a7270', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.3()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "20c99119c82f2feb2f8c20e68bf9551a", "grade": false, "grade_id": "cell-bfd0d54d4d051503", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.4**
<br>{points: 1}

True or false?

Multicollinearity inflates the estimates of the standard errors of the least squares (LS) estimators of the regression coefficients.

*Assign your answer to an object called `answer1.4`. Your answer should be either "true" or "false", surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '3d5814ef6c366a3b35c06e25b7fa80e9', 'grade': False, 'grade_id': 'cell-77075476489b956d', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.4 <- ...

# your code here
answer1.4 <- "true"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f283e016fb5bfb61bb1e3ba7fcd6dc51', 'grade': True, 'grade_id': 'cell-b1048804f31dc9ea', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.4()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ec363abb045f81d519817f505d2df230", "grade": false, "grade_id": "cell-9c2b725ee6ef8b19", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.5**
<br>{points: 1}

True or false?

The assumption that all the error terms have the same variance does not affect the estimates of the standard error of the LS estimators.

*Assign your answer to an object called `answer1.5`. Your answer should be either "true" or "false", surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '27a858948e265422862427b63a146712', 'grade': False, 'grade_id': 'cell-71b8eca6f72e054f', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.5 <- ...

# your code here
answer1.5 <- "false"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f728f1c9afde6acaf0de394ba7f5a824', 'grade': True, 'grade_id': 'cell-212dc805b92990b7', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.5()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "cd78ee589fd005aaebd3ac9d6693c932", "grade": false, "grade_id": "cell-f0cfb1b73cd006ea", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 2. Violations of model assuptions


In the following problems we will explore how violations of model assumptions affect our estimation and analyses *using simulated data*. 

> The advantage of simulating data is that we have full control over the data generating process so **we know the true parameters** and we can examine problems in a control way. 

Real datasets are rich and interesting but usually contain many (unknown) problems and we don't know the true parameters to assess the performance of our estimation and analyses. 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "a9fa18cfeeec388568431b675250b530", "grade": false, "grade_id": "cell-f83f4cfc44d53d11", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### Bechmark model
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "41e7d9221d33d96747036132c380a6f6", "grade": false, "grade_id": "cell-0352fabc6efebd45", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.0**
<br>{points: 1}

Let's start by generating a sample of size $n = 1000$ from a data generating process that *fullfills all the assumptions* of classical least square estimation in linear regression.

In this problem we generate data from a continuous response, one continuous input variable and one binary input variable. We call this first sample `sample_model_1`.

That is, for $i = 1, \dots, n$:

$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \varepsilon_i$$ 

where the error terms $\varepsilon_i \sim \mathcal{N}(0, \sigma^2 = 4)$ are independent and identically distributed. Assume that $X_{1}$ is uniformly distributed between 2 and 5, and $X_{2}$ is a binary random variable with levels "A" and "B" (with equal probabilty).

Generate a response variable using these model assumptions and true (population) regression coefficients $\beta_0$, $\beta_1$, and $\beta_2$ equal to $10$, $8$, and $5$, respectively. 

> **Heads up**: the distributions used to generate the input variables do not affect the results of our analysis. 

Note that the columns of `sample_model_1` are:

- `x_1`: the values of the continuous input $X_{i1}$
- `x_2`: the levels of the discrete input $X_{i2}$
- `y`: the sampled response values $Y_i$

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'd1488dc46acdd3e02a7a68ac8036bce8', 'grade': False, 'grade_id': 'cell-5005e2d15ce1ed92', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
sample_size <- 1000

set.seed(123) # DO NOT CHANGE!

# sample_model_1 <- tibble(
#   x_1 = runif(n = ..., ..., ...),
#   x_2 = factor(rbinom(n = ..., size = 1, prob = 0.5), labels=c("A", "B"))
# )
# sample_model_1$y <- ... + 8 * sample_model_1$x_1 + 5 * ifelse(sample_model_1$x_2 == "B", 1, 0) +
#   rnorm(n = ..., mean = ..., sd = ...)
# head(sample_model_1)

# your code here
sample_model_1 <- tibble(
  x_1 = runif(n = 1000, min = 2, max = 5),
  x_2 = factor(rbinom(n = 1000, size = 1, prob = 0.5), labels=c("A", "B"))
)
sample_model_1$y <- 10 + 8 * sample_model_1$x_1 + 5 * ifelse(sample_model_1$x_2 == "B", 1, 0) +
  rnorm(n = 1000, mean = 0, sd = 2)
head(sample_model_1)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '58b8e35732e1c3074bc4fc02f26dbe96', 'grade': True, 'grade_id': 'cell-4cb5c9662c07edb1', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.0()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "b2525dbb6b25c14ae9a15237dcd4948a", "grade": false, "grade_id": "cell-37e2698a76960ba7", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.1**
<br>{points: 1}

Use the simulated `sample_model_1` to estimate the regression parameters $\beta_0$, $\beta_1$, and $\beta_2$ and elements to make inference using hypothesis tests. Use the functions `lm()` and assign the results to the object `model_1`.

Obtain the estimated coefficients, their standard errors, corresponding $p$-values, $95\%$ confidence intervals using `tidy()`. Store the results in `model_1_results`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1a107e81a5296f31f09d845b195a476c', 'grade': False, 'grade_id': 'cell-11ac5eb8d9e9032c', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# model_1 <- ...(..., ...)

# model_1_results <- ...(..., ...) %>% mutate_if(is.numeric, round, 2)
# model_1_results

# your code here
model_1 <- lm(y ~ x_1 + x_2 , data = sample_model_1)

model_1_results <- tidy(model_1, conf.int = 0.95) %>% mutate_if(is.numeric, round, 2)
model_1_results
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '7d09b65e79e9ec69614d77f7dd8718fc', 'grade': True, 'grade_id': 'cell-326617182b53a8b9', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "13091a266db20f255c6631b80b5a08f0", "grade": false, "grade_id": "cell-453527ccc61f4adf", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Note that the estimates $\hat{\beta}_0$,  $\hat{\beta}_1$, and $\hat{\beta}_2$ in `model_1` are close to the true population parameters (less than 2 standard errors away). At least for this sample, all 95% confidence intervals contain the true parameters that we've used to generate the data.

> **Heads up**: in general, we don't know the true parameters to make this type of assessment.

> **Heads up**: even with simulated data, the estimated CI may not contain the true parameters. Why??
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "6e7c8936c8384dcb0943c1fc35732cc4", "grade": false, "grade_id": "cell-9939f20b71f46f90", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### Heteroscedasticity

In the previous case, we assume that the error terms were independent and identically distributed. *What would happen if this assumption is violated in the data??*

In particular, we will focus on a problem known as *heteroscedasticity*.

In the next question, we are going to simulate data from a *data generating process with heteroscedasticity* and use `lm` to estimate the coefficients of the MLR ignoring that the error terms are heteroscedastic.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "7b2334491dfdae31f89c5f64c38d921a", "grade": false, "grade_id": "cell-774140056a754948", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.2**
<br>{points: 1}

We generate a sample of size $n = 1000$ from a data generating process with the following characteristics:

For $i = 1, \dots, n$:

$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \varepsilon_i$$ 

where the error terms $\varepsilon_i \sim \mathcal{N}(0, \sigma_i^2 = (X_{i1})^4)$. The variables $X_{i1}$ and $X_{i2}$ are generated as in **Question 2.0**.

> **There is heteroscedasticity (i.e., the value of $\sigma_i^2$ is different for each observation).**

As before, let the true (population) regression terms $\beta_0$, $\beta_1$, and $\beta_2$ be $10$, $8$, and $5$. 

Call this new sample `sample_model_2`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'ed5ad181a17f99aca2b7710580322f17', 'grade': False, 'grade_id': 'cell-7be37d4514cec87d', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(321) # DO NOT CHANGE!

# sample_size = ...

# sample_model_2 <- tibble(
#   x_1 = runif(n = ..., ..., ...),
#   x_2 = factor(rbinom(n = ..., size = ..., prob = ...), labels=c("A", "B"))
# )
# sample_model_2$y <- ... + ... * sample_model_2$... + 5 * ifelse(sample_model_2$... == "B", 1, 0) +
#   rnorm(n = ..., mean = ..., sd = (sample_model_2$...)^2)
# head(sample_model_2)

# your code here
sample_size = 1000

sample_model_2 <- tibble(
  x_1 = runif(n = sample_size, min = 2, max = 5),
  x_2 = factor(rbinom(n = 1000, size = 1, prob = 0.5), labels=c("A", "B"))
)
sample_model_2$y <- 10 + 8 * sample_model_2$x_1 + 5 * ifelse(sample_model_2$x_2 == "B", 1, 0) +
  rnorm(n = sample_size, mean = 0, sd = (sample_model_2$x_1)^2)
head(sample_model_2)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'cff9148c006c237c0511d19363454b9f', 'grade': True, 'grade_id': 'cell-fa963f6510742705', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.2()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "dc6b7942be3da1ad1741fe92a3235377", "grade": false, "grade_id": "cell-2554fcc8ead9b506", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.3**
<br>{points: 1}

Use the simulated `sample_model_2` to estimate the regression parameters $\beta_0$, $\beta_1$, and $\beta_2$ and elements to make inference using hypothesis tests. 

*Ignore the heteroscedasticity of the data generating process* and use the function `lm()` to estimate the regression parameters. Assign the results to the object `model_2`.

Obtain the estimated coefficients, their standard errors, corresponding $p$-values, $95\%$ confidence intervals using `tidy()`. Store the results in `model_2_results`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '9b34cd68e9b37b1aa21937edc476568d', 'grade': False, 'grade_id': 'cell-a4752931d34821b5', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# model_2 <- ...(..., ...)

# model_2_results <- ...(..., ...) %>% mutate_if(is.numeric, round, 2)
# model_2_results

# your code here
model_2 <- lm(y ~ x_1 + x_2, data = sample_model_2)

model_2_results <- tidy(model_2, conf.int = 0.95) %>% mutate_if(is.numeric, round, 2)
model_2_results


```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '8a5cdbf8fe599a17aadaac1e5d186713', 'grade': True, 'grade_id': 'cell-cb5ea4ece832800f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.3()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f6bd6d476ffdd74e0d048a895784e086", "grade": false, "grade_id": "cell-358b448fd8b907f1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.4**
<br>{points: 1}

Recall that the true population values of $\beta_0$, $\beta_1$, and $\beta_2$ are $10$, $8$, and $5$ respectively.  What of the following consequences of ignoring the heteroscedasticity of the data generating process is true? 

*Tip*: `lm` assumes that the errors are *iid* as in `sample_model_1`. Thus, you can also use `model_1_results` as a benchmark.

**A.** The estimates $\hat{\beta}_0$,  $\hat{\beta}_1$, and $\hat{\beta}_2$ in `model_2_results` are still similar to the true population parameters but their estimated standard errors are inflated.

**B.** The 95% confidence intervals of the regression coefficients are not affected by the heteroscedasticity of the data generating process.


*Assign your answer to an object called `answer2.4`. Your answer should be one of `"A"` or `"B"` surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '95d51245afb105007678da849da902ed', 'grade': False, 'grade_id': 'cell-03200e468b4ed9a7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer2.4 <- 

# your code here
answer2.4 <- "A"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '44327cb5496dd09bdef564ddfc4235ec', 'grade': True, 'grade_id': 'cell-d4fa23719518cfae', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.4()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "bcb3ec24c0efbe6d64d4b5038b93f355", "grade": false, "grade_id": "cell-e51a3e421545b891", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Detecting heteroscedasticity

When we don't have simulated data, we can (graphically) diagnose heteroscedasticity by comparing the fitted values to the **residuals**. 

<font color="blue">**Diagnosis rule**</font>

<font color="blue">If the errors are homoscedastic (equal variance), the residuals should show equal variation for all fitted values. </font>

Let's take a look at these plots for both cases simulated before: `model_1` (homoscedastic case) versus `model_2` (heteroscedastic case). We can obtain both plots via the function `plot()`.

*Run the cell below before continuing.*
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'fc647623aef53ad5725734234e00a1af', 'grade': False, 'grade_id': 'cell-f9d678639aeb4975', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
plot(model_1, 1, main = "Model 1: homoscedastic")
plot(model_2, 1, main = "Model 2: heteroscedastic")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "e4d2b4b63e35bd55a0d905efdaf82436", "grade": false, "grade_id": "cell-2423a377827ef0db", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.5**
<br>{points: 1}

What is the difference between both plots of residuals versus fitted values?

**A.** There is no difference between both plots; their respective clouds of points look uniformly similar.

**B.** The diagnostic plot of `model_1` shows a uniform and more scattered cloud of points than `model_2`. The cloud of points in `model_2` shows a clear funnel shape, indicating a non-constant variance.

**C.** The diagnostic plot of `model_2` shows a uniform and more scattered cloud of points than `model_1`. The cloud of points in `model_1` shows a clear funnel shape, indicating a non-constant variance.

*Assign your answer to an object called `answer2.5`. Your answer should be one of `"A"`, `"B"`, or `"C"` surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'eb4cd9b3ecfb74656a7b6006dff1ff6a', 'grade': False, 'grade_id': 'cell-0ac7451d1055fdcd', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer2.5 <- 

# your code here
answer2.5 <- "B"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '26c1767686eff9f79a7b5517f3fe86b8', 'grade': True, 'grade_id': 'cell-a0823aa644741ac9', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.5()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "0dd253a4dd3411f1cb4741c87c95fa4d", "grade": false, "grade_id": "cell-32a44b64fde55ec7", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### Normality

Another assumption commonly made in linear regression is that the error terms are Normally distributed. *What would happen if this assumption is violated??*. 

In the next question, we are going to simulate data using a data generating process with non-normal errors and use `lm` to estimate the coefficients of the MLR.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "83a68854560edb52502bf68c3c6a1334", "grade": false, "grade_id": "cell-0583e55524bbbff4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.6**
<br>{points: 1}

For $i = 1, \dots, 1000$:

$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \varepsilon_i,$$

where the error terms are independent and identically distributed from a Uniform distribution, $\varepsilon_i \sim \mathrm{U}(-10,10)$. The variables $X_{i1}$ and $X_{i2}$ are generated as in **Question 2.0**.

As before, let the true (population) regression terms $\beta_0$, $\beta_1$, and $\beta_2$ be $10$, $8$, and $5$, respectively, and the sample size $n=1000$.

Call this new sample `sample_model_3`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '6b3441295921b6f457f37b963e83f3d0', 'grade': False, 'grade_id': 'cell-f4f0d75b03d87416', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(654) # DO NOT CHANGE!

# sample_size = ...

# sample_model_3 <- tibble(
#   x_1 = runif(n = ..., ..., ...),
#   x_2 = factor(rbinom(n = ..., size = ..., prob = ...), labels=c("A", "B"))
# )
# sample_model_3$y <- ... + .. * sample_model_3$... + 5 * ifelse(sample_model_3$... == "B", 1, 0) +
# runif(n = ..., ..., ...)
# head(sample_model_3)

# your code here
sample_size = 1000

sample_model_3 <- tibble(
  x_1 = runif(n = sample_size, min = 2, max = 5),
  x_2 = factor(rbinom(n = sample_size, size = 1, prob = 0.5), labels=c("A", "B"))
)
sample_model_3$y <- 10 + 8 * sample_model_3$x_1 + 5 * ifelse(sample_model_3$x_2 == "B", 1, 0) +
runif(n = sample_size, min = -10, max = 10)
head(sample_model_3)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '94da43d13c406c42ae5f5498362f7867', 'grade': True, 'grade_id': 'cell-4daac39e2a263638', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.6()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "cf49c4e696558afdc750dec91a0ffb0f", "grade": false, "grade_id": "cell-31286491f37e5adf", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.7**
<br>{points: 1}

Use the simulated `sample_model_3` to estimate the regression parameters $\beta_0$, $\beta_1$, and $\beta_2$ and elements to make inference using hypothesis tests. 

Use the function `lm()` to estimate the regression parameters. Assign the results to the object `model_3`.

Obtain the estimated coefficients, their standard errors, corresponding $p$-values, $95\%$ confidence intervals using `tidy()`. Store the results in `model_3_results`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'e5b1766ed676a52d0db1f4ec86d9a92e', 'grade': False, 'grade_id': 'cell-265c75bbb081eb6f', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# model_3 <- ...(..., ...)

# model_3_results <- ...(..., ...) %>% mutate_if(is.numeric, round, 2)
# model_3_results

# your code here
model_3 <- lm(y ~ x_1 + x_2, data = sample_model_3)

model_3_results <- tidy(model_3, conf.int = 0.95) %>% mutate_if(is.numeric, round, 2)
model_3_results
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'd4c82e1490254a35bd2affc37305e8db', 'grade': True, 'grade_id': 'cell-9cc9196c59e66f46', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.7()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "058df6abbe9a7abcf5b09bd5c12cc91a", "grade": false, "grade_id": "cell-e68f5ba3f0ccd35f", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Note that the estimate of the regression parameters are not heavily affected by this problem but the SE are large. 

The distributions of the test statistics such as the $t$ or the $F$-statistics rely on the normality of the $\varepsilon_i$'s, unless the sample size $n$ is large enough in which case their distribution can be approximated using asymptotic results. 

#### In this case, the sample size is large so, according to the CLT, the sampling distributions when $\sigma$ is known is approximately Normal. 

> **Important note**: `lm` *assumes* that either the errors are Normal or the conditions of the CLT are met!! Regardless, `lm` assumes that the sampling distribution can be approximated by a $t$-Student distribution. It is *your* job to check these assumptions!
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "fe7e20057ef89537ddd09e007215d941", "grade": false, "grade_id": "cell-8ae11e452b9ab56f", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Diagnostic plots

A $Q$-$Q$ plot and the histogram of residuals are graphical tools that help us to assess the normality assumption.

Let us compare these plots for `model_1` (with Normal errors) and `model_3` (with non-Normal errors). We can obtain both $Q$-$Q$ plots via the function `plot()` and the histograms using `hist()`.

*Run the cell below before continuing.*
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'd82d8d2e367839e34cf600d164e0467f', 'grade': False, 'grade_id': 'cell-376408f168bc4a00', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
plot(model_1, 2, main = "Model 1")
hist(residuals(object = model_1),
  breaks = 10,
  main = "Histogram of Residuals for Model 1",
  xlab = "Residuals"
)

plot(model_3, 2, main = "Model 3")
hist(residuals(object = model_3),
  breaks = 10,
  main = "Histogram of Residuals for Model 3",
  xlab = "Residuals"
)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "77f3ae18f02298e9290f851e1a785754", "grade": false, "grade_id": "cell-3ef9ae8e1ccaf538", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.8**
<br>{points: 1}


What is the difference between both pairs plots corresponding to `model_1` and `model_3`?

**A.** There are no differences between both pairs of plots, suggesting that both models fulfil the normality assumption.

**B.** For `model_3`, most of the points lie on the 45° degree dotted line of the $Q$-$Q$ plot suggesting that the errors are normally distributed. 

**C.** For `model_1`, most of the points lie on the 45° degree dotted line of the $Q$-$Q$ plot suggesting that the errors are normally distributed. 

**D.** The histogram of the residuals of `model_3` is similar to that of the residuals of `model_1`. 

*Assign your answer to an object called `answer2.8`. Your answer should be one of `"A"`, `"B"`, `"C"`, or `"D"`, surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'd2e15a9127b3585740feb0b86d9af094', 'grade': False, 'grade_id': 'cell-322d6b07e2c76409', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer2.8 <- 

# your code here
answer2.8 <- "C"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'fdfb555f3520894054f01fc6f02771d7', 'grade': True, 'grade_id': 'cell-7cfdd3595723b330', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.8()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "243740c20bb5383c3f56531d981721ad", "grade": false, "grade_id": "cell-f3685cd190b2a48e", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
### Multicollinearity

A common problem in real data occurs when the input variables are correlated. This problem is known as multicollinearity. In this section we will simulate correlated input variables to understand how this problem affects the sampling distribution of the least squares regression parameter estimators.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "8c94abc3badf83e716e1d4f38b0c105d", "grade": false, "grade_id": "cell-08094e7e680afc80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
In this exercise, we will generate 1000 samples of size $n = 100$ from the following data generating process:

For $i = 1, \dots, n$,

$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \varepsilon_i$$ 

where the error terms $\varepsilon_i \sim \mathcal{N}(0, \sigma^2 = 4)$ are independent and identically distributed, and $X_{1}$ and $X_{2}$ are two continuous correlated input variables. 

Assume that all the true (population) regression terms $\beta_0$, $\beta_1$, and $\beta_2$ are equal to $10$. 

**Note**: note that $n$ and the regression coefficients are different in this problem.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "3df931221f81c54fbc3343f392399009", "grade": false, "grade_id": "cell-c521effc05929e77", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.9**
<br>{points: 1}

First, let's learn how to generate correlated inputs $X_{1}$ and $X_{2}$ from a bivariate normal distribution. Assume these variables have population means $\mu_1 = 10$ and $\mu_2 = 20$, respectively. Furthermore, their respective population standard deviations are $\sigma_1 = 4$ and  $\sigma_2 = 8$ and a correlation $\rho = 0.95$ to generate multicollinearity.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b638290b6950ecd443bc48129ed8b1e2', 'grade': False, 'grade_id': 'cell-1f1c93e7aa03af7d', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(456) # DO NOT CHANGE!

# sample_size <- ...
# bivariate_normal_sample <- rnorm_multi(
#   n = ...,
#   mu = c(...,...),
#   sd = c(...,...),
#   r = ...,
#   varnames = c("x_1", "x_2"),
#   empirical = FALSE
# )

# head(bivariate_normal_sample)

# your code here
sample_size <- 100
bivariate_normal_sample <- rnorm_multi(
  n = sample_size,
  mu = c(10,20),
  sd = c(4,8),
  r = 0.95,
  varnames = c("x_1", "x_2"),
  empirical = FALSE
)

head(bivariate_normal_sample)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b42ddefaf3fe2f44a4d4bc02a6b2eaad', 'grade': True, 'grade_id': 'cell-da29435913bf774f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.9()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "69e3607cdc613a25eed999c57263847a", "grade": false, "grade_id": "cell-db19c531325127ad", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.10**
<br>{points: 1}

Now we generate $1000$ datasets of size $n=100$ from the data generating process described and fit an additive MLR using `lm` to each dataset. 

Store the corresponding $\hat{\beta}_0$, $\hat{\beta}_1$, and $\hat{\beta}_2$ per sample in a dataframe called `lm_multicollinearity` of 1000 rows and three columns:

- intercept: The estimated intercept $\hat{\beta}_0$.
- beta_1_hat: The estimated slope $\hat{\beta}_1$.
- beta_2_hat: The estimated slope $\hat{\beta}_2$.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'c2d781b06f596d4ff8ab827800941b40', 'grade': False, 'grade_id': 'cell-7fc8624a0cab3f0e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(321) # DO NOT CHANGE!

# sample_size <- ...
# num_replicates <- ...

# beta_0 <- ...
# beta_1 <- ...
# beta_2 <- ...

# lm_multicollinearity <- replicate(..., {
#   rnorm_multi(
#     n = ...,
#     mu = ...,
#     sd = ...,
#     r = ...,
#     varnames = c("x_1", "x_2"),
#     empirical = FALSE
#   ) %>%
#     mutate(y = ... + beta_1 * ... + ... * x_2 +
#       rnorm(n = ..., mean = 0, sd = ...)) %>%
#     lm(..., data = .) %>%
#     .$coef
# })
# lm_multicollinearity <- data.frame(
#   intercept = lm_multicollinearity[1, ],
#   beta_1_hat = lm_multicollinearity[2, ],
#   beta_2_hat = lm_multicollinearity[3, ]
# )

# head(lm_multicollinearity)

# your code here
sample_size <- 100
num_replicates <- 1000

beta_0 <- 10
beta_1 <- 10
beta_2 <- 10

lm_multicollinearity <- replicate(num_replicates, {
  rnorm_multi(
    n = sample_size,
    mu = c(10, 20),
    sd = c(4, 8),
    r = 0.95,
    varnames = c("x_1", "x_2"),
    empirical = FALSE
  ) %>%
    mutate(y = beta_0 + beta_1 * x_1 + beta_2 * x_2 +
      rnorm(n = sample_size, mean = 0, sd = 2)) %>%
    lm(y ~ x_1 + x_2, data = .) %>%
    .$coef
})
lm_multicollinearity <- data.frame(
  intercept = lm_multicollinearity[1, ],
  beta_1_hat = lm_multicollinearity[2, ],
  beta_2_hat = lm_multicollinearity[3, ]
)

head(lm_multicollinearity)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '43e77fda17fd422ccc63fb0fcd8c3ee9', 'grade': True, 'grade_id': 'cell-a3ad21c32c86b702', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.10()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f94afd8446121a758876a724f077fcd2", "grade": false, "grade_id": "cell-a420aafa6b0d76a6", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.11**
<br>{points: 1}

For comparison purposes, repeat the process for samples taken from a population without multicollinearity (use $\rho = 0.001$).

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '80a44c34cb1bff522768834abe95b914', 'grade': False, 'grade_id': 'cell-a62dc494d2cb00f0', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(321) # DO NOT CHANGE!

# sample_size <- ...
# num_replicates <- ...

# beta_0 <- ...
# beta_1 <- ...
# beta_2 <- ...

# lm_no_multicollinearity <- replicate(..., {
#   rnorm_multi(
#     n = ...,
#     mu = ...,
#     sd = ...,
#     r = ...,
#     varnames = c("x_1", "x_2"),
#     empirical = FALSE
#   ) %>%
#     mutate(y = ... + beta_1 * ... + ... * x_2 +
#       rnorm(n = ..., mean = 0, sd = ...)) %>%
#     lm(..., data = .) %>%
#     .$coef
# })
# lm_no_multicollinearity <- data.frame(
#   intercept = lm_no_multicollinearity[1, ],
#   beta_1_hat = lm_no_multicollinearity[2, ],
#   beta_2_hat = lm_no_multicollinearity[3, ]
# )

# head(lm_no_multicollinearity)

# your code here
sample_size <- 100
num_replicates <- 1000

beta_0 <- 10
beta_1 <- 10
beta_2 <- 10

lm_no_multicollinearity <- replicate(num_replicates, {
  rnorm_multi(
    n = sample_size,
    mu = c(10, 20),
    sd = c(4, 8),
    r = 0.001,
    varnames = c("x_1", "x_2"),
    empirical = FALSE
  ) %>%
    mutate(y = beta_0 + beta_1 * x_1 + beta_2 * x_2 +
      rnorm(n = sample_size, mean = 0, sd = 2)) %>%
    lm(y ~ x_1 + x_2, data = .) %>%
    .$coef
})
lm_no_multicollinearity <- data.frame(
  intercept = lm_no_multicollinearity[1, ],
  beta_1_hat = lm_no_multicollinearity[2, ],
  beta_2_hat = lm_no_multicollinearity[3, ]
)

head(lm_no_multicollinearity)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '69f61eedef6f89bca497c8506ae8f56d', 'grade': True, 'grade_id': 'cell-79f290838673f039', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.11()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "e2318ca77e95952a65b1307d65f7e68e", "grade": false, "grade_id": "cell-afc49b8f8185ea46", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.12**
<br>{points: 1}

Plot the 1000 regression estimates for the slope corresponding to $X_1$ (i.e., $\hat{\beta}_1$) stored in `lm_multicollinearity` and `lm_no_multicollinearity`, separately (i.e., two histograms with counts on the $y$-axis and the estimate on the $x$-axis). 

Call the ggplot() object's names `hist_multicollinearity_slope_x_1` and `hist_no_multicollinearity_slope_x_1`, respectively. Moreover, plot the averages of these estimates in their respective histograms as vertical red lines.

**Note**: these are not bootstrapped estimates!

*Fill out those parts indicated with ..., uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'eefc39793f2088885805f0d9ed4ed0b1', 'grade': False, 'grade_id': 'cell-567626205f418eb8', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
options(repr.plot.width = 15, repr.plot.height = 7) # Adjust these numbers so the plot looks good in your desktop.

# hist_multicollinearity_slope_x_1 <- ggplot(..., aes(...)) +
#   ...(bins = 15, color = "black", fill = "blue") +
#   ...(..., col = "red", size = 1) +
#   coord_cartesian(xlim = c(9.4, 10.6), ylim = c(0, 250)) +
#   scale_x_continuous(breaks = seq(9, 10.6, 0.2)) +
#   xlab(...) +
#   ylab(...) +
#   theme(
#     text = element_text(size = 19),
#     plot.title = element_text(face = "bold"),
#     axis.title = element_text(face = "bold")
#   ) +
#   ggtitle(...)

# hist_no_multicollinearity_slope_x_1 <- ggplot(..., aes(...)) +
#   ...(bins = 15, color = "black", fill = "blue") +
#   ...(..., col = "red", size = 1) +
#   coord_cartesian(xlim = c(9.4, 10.6), ylim = c(0, 250)) +
#   scale_x_continuous(breaks = seq(9, 10.6, 0.2)) +
#   xlab(...) +
#   ylab(...) +
#   theme(
#     text = element_text(size = 19),
#     plot.title = element_text(face = "bold"),
#     axis.title = element_text(face = "bold")
#   ) +
#   ggtitle(...)

# plot_grid(hist_multicollinearity_slope_x_1, hist_no_multicollinearity_slope_x_1,
#   ncol = 2
# )

# your code here
hist_multicollinearity_slope_x_1 <- ggplot(lm_multicollinearity, aes(beta_1_hat)) +
  geom_histogram(bins = 15, color = "black", fill = "blue") +
  geom_vline(aes(xintercept = mean(beta_1_hat)), col = "red", size = 1) +
  coord_cartesian(xlim = c(9.4, 10.6), ylim = c(0, 250)) +
  scale_x_continuous(breaks = seq(9, 10.6, 0.2)) +
  xlab("Estimate") +
  ylab("Count") +
  theme(
    text = element_text(size = 19),
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  ) +
  ggtitle("Multicollinearity of Slope Estimate")

hist_no_multicollinearity_slope_x_1 <- ggplot(lm_no_multicollinearity, aes(beta_1_hat)) +
  geom_histogram(bins = 15, color = "black", fill = "blue") +
  geom_vline(aes(xintercept = mean(beta_1_hat)), col = "red", size = 1) +
  coord_cartesian(xlim = c(9.4, 10.6), ylim = c(0, 250)) +
  scale_x_continuous(breaks = seq(9, 10.6, 0.2)) +
  xlab("Estimate") +
  ylab("Count") +
  theme(
    text = element_text(size = 19),
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  ) +
  ggtitle("No Multicollinearity of Slope Estimate")

plot_grid(hist_multicollinearity_slope_x_1, hist_no_multicollinearity_slope_x_1,
  ncol = 2
)

```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '11f882cc73db3cd4f917861eba656c27', 'grade': True, 'grade_id': 'cell-7660d122189e5eb7', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.12.0()
test_2.12.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "819a3d1168caf1e5db43aa54254f79dc", "grade": false, "grade_id": "cell-a3e0187538a817b4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 2.13**
<br>{points: 1}

Based on your findings in `hist_multicollinearity_slope_x_1` and `hist_no_multicollinearity_slope_x_1`, what are the implications of multicollinearity in the sampling distributions of least squares estimators of MLR?

**A.** The multicollinearity reduces the standard error of the regression estimator.

**B.** Multicollinearity inflates the standard error of the regression estimator.

**C.** Multicollinearity does not seems to affect the estimation results.

*Assign your answer to an object called answer2.13. Your answer should be one of `"A"`, `"B"`, or `"C"` surrounded by quotes.*

<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '13b713c0cf385afb64f43459cbd7e5f0', 'grade': False, 'grade_id': 'cell-13a2606b42741a5e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer2.13 <- ...

# your code here
answer2.13 <- "B"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1daf53f752a5168dd55f721862930e77', 'grade': True, 'grade_id': 'cell-93b7a249a29267bc', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_2.13()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "0c456b0038c8fc6a5e6b0f4d21150f6a", "grade": false, "grade_id": "cell-ddd9186d674cb006", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# PART II
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "657d625d718ca722fd619c70f1526a6e", "grade": false, "grade_id": "cell-d10e1df65f09d941", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 2.  Causality and Confounders
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "578987c1f6bfa5f29a606cc0dca678c7", "grade": false, "grade_id": "cell-077e39907f4cfbe1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
You will work on a simulation experiment outlined in `tutorial_05`.
<!-- #endregion -->
