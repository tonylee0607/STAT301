---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "b109521d10c23498d74b7495022f6601", "grade": false, "grade_id": "cell-f1e1d845873036f4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# Tutorial 13: Classifiers as an Important Class of Predictive Models
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "cca84cb3ce52ad19008100efebf7400a", "grade": false, "grade_id": "cell-82d9926086d47a80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
#### Lecture and Tutorial Learning Goals:
After completing this week's lecture and tutorial work, you will be able to:

1. Give an example of a research question that requires a predictive model to predict classes on new observations.
2. Explain the trade-offs between model-based and non-model based approaches, and describe situations where each might be the preferred approach.
3. Write a computer script to perform model selection using ridge and LASSO regressions to fit a logistic regression useful for predictive modeling.
4. List model metrics that are suitable to evaluate predicted classes given by a predictive model with binary responses (e.g., Accuracy, Precision, Sensitivity, Specificity, Cohen's kappa).
5. Write a computer script to compute these model metrics. Interpret and communicate the results from that computer script.
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '2bd086667026885e88edcc725b896489', 'grade': False, 'grade_id': 'cell-a2a153352bc44a68', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing.
library(tidyverse)
library(repr)
library(infer)
library(gridExtra)
library(caret)
library(pROC)
library(boot)
library(glmnet)
source("tests_tutorial_13.R")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "f29cd3c20ca5c183c7afb35d160cd633", "grade": false, "grade_id": "cell-fd783bc5ce404c85", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
For this tutorial, we will keep working with the `breast_cancer` data set. 
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'bbf52dced6457521da691636e97389bb', 'grade': False, 'grade_id': 'cell-f577c5adc888b891', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing

set.seed(20211130)

breast_cancer <- read_csv("data/breast_cancer.csv") %>%
    select(-c(
        mean_area, area_error, concavity_error, concave_points_error, worst_radius, worst_texture, worst_perimeter,
        worst_area, worst_smoothness, worst_compactness, worst_concavity, worst_concave_points, worst_symmetry,
        worst_fractal_dimension)) %>% 
    mutate(target = if_else(target == "malignant", 1, 0))

breast_cancer_train <- 
    breast_cancer %>% 
    slice_sample(prop = 0.70)

breast_cancer_test <- 
    breast_cancer %>% 
    anti_join(breast_cancer_train, by = "ID")

breast_cancer_train <- 
    breast_cancer_train %>% 
    select(-ID)

breast_cancer_test <- 
    breast_cancer_test %>% 
    select(-ID)

breast_cancer_logistic_model <- 
    glm(
        formula = target ~ .,
        data = breast_cancer_train,
        family = binomial)

ROC_full_log <- 
    roc(
        response = breast_cancer_train$target, 
        predictor = predict(breast_cancer_logistic_model, type = "response"))
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ad31a0a1d9cd2ab811e9cddaa87890ee", "grade": false, "grade_id": "cell-f72168f336dccb06", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
In the worksheet, you fitted the regular logistic regression to this data set. But, we can also use *shrinkage methods* in binary logistic regression. Shrinkage methods aim to improve your model by introducing some bias in exchange for a reduction in the model's variance. In general, we have the loss function that we are trying to minimize, and the shrinkage methods add a penalty term to it:

- *Ridge loss function* $ = Loss(\beta) + \lambda||\beta||_2$
    - For example, for linear regression we have $  L_\text{Ridge}(\beta)= \sum_{i=1}^N \left(y_i - \beta_0 - \sum_{j=1}^p\beta_jX_{ij}\right)^2 + \lambda\sum_{j=1}^p\beta_j^2$
    
    
- *Lasso loss function* $ = Loss(\beta) + \lambda||\beta||_1$
    - For example, for linear regression we have $ L_\text{Lasso}(\beta) = \sum_{i=1}^N \left(y_i - \beta_0 - \sum_{j=1}^p\beta_jX_{ij}\right)^2 + \lambda\sum_{j=1}^p|\beta_j|$

For the logistic regression we have:

$$L_{\text{Ridge}}(\beta_0, \beta_1, \dots, \beta_{p-1}) = - \sum_{i = 1}^n  \Bigg\{ -\log \Bigg[ 1 + \exp \Bigg(\beta_0 + \sum_{j = 1}^{p -1}\beta_j x_{ij} \Bigg) \Bigg] + y_i \Bigg( \beta_0 + \sum_{j = 1}^{p -1}\beta_j x_{ij} \Bigg) \Bigg\} + \lambda \sum_{j = 1}^{p - 1} \beta_j^2,$$

- *Note: don't worry about these functions; we are adding them here just FYI.*
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ab9bd212f98a74378f1aa329a97e4186", "grade": false, "grade_id": "cell-13bcacdf5557880e", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
The package `glmnet` takes variables only as matrices. Therefore, we need to prepare our data before fitting the regularized models using `glmnet`.
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "195b59cd4b020c9605e98ac87ec0273c", "grade": false, "grade_id": "cell-cf386c1a245ac102", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.0**
<br>{points: 1}

To prepare the model matrix for `glmnet`, we will use the `model.matrix` function, which receives two arguments:

- `object`: which is the formula of your model.
- `data`: which is the data you want to use.

The `model.matrix` function adds a column named `(Intercept)` filled with ones. We do not need this column, so let's remove it. We will also need the response variable to be in a matrix format, so let's create this now. 

Save the model matrix in an object named `model_matrix_X_train` and the response matrix in an object named `matrix_Y_train`. 

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'a4f67b4798840b3853afd514e6ba5b1e', 'grade': False, 'grade_id': 'cell-8cb6ee2b2c7af17a', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# model_matrix_X_train <- 
#     ...

# matrix_Y_train <- 
#     as.matrix(..., ncol = 1)

# your code here
model_matrix_X_train <- 
    model.matrix(object = target ~ . -1, data = breast_cancer_train)

matrix_Y_train <- 
    as.matrix(breast_cancer_train$target, ncol = 1)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1651a13d44e37b716703d8159c9f1fd8', 'grade': True, 'grade_id': 'cell-9329daabcca68052', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.0()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "2b9a4f8bd4759f43d522c5def4e3f5f4", "grade": false, "grade_id": "cell-d1d061fedea199cf", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## Ridge Regression
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "47562d4108e73335b1a706b282b8abd4", "grade": false, "grade_id": "cell-b81ad428712384f1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.1**
<br>{points: 1}

Once we have our training data prepared in `model_matrix_X_train` and `matrix_Y_train`, let us find the value of $\lambda$ in $L_{\text{Ridge}}(\beta_0, \beta_1, \dots, \beta_{p})$ that provides the **largest** AUC using **cross-validation** (CV). 

The function `cv.glmnet()` runs a cross-validation for any estimator in the `glmnet` family. The data is divided into $k$ folds. An AUC is computed in one fold left out using a model that is trained in the remaining folds. This calculation is repeated for all folds so you get $k$ AUC values for each $\lambda$ in the grid.

Recall that ridge regression is defined when `alpha` is equal to zero. 

In this questions, use `auc` as the `type.measure` to measure prediction performance, and set the number of folds `nfolds` to 10. 

Note that the other arguments are the same as we used before to fit a Ridge linear regression model.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '16c388e1a80e2d8d1fd8978ca1b168c5', 'grade': False, 'grade_id': 'cell-798fffbe7429d3a4', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(1234) # do not change this!

# breast_cancer_cv_lambda_ridge <- 
#   cv.glmnet(
#        x = ..., 
#        y = ...,
#        alpha = ...,
#        family = ...,
#        type.measure = ...,
#        nfolds = ...)

# breast_cancer_cv_lambda_ridge 

# your code here
breast_cancer_cv_lambda_ridge <- 
  cv.glmnet(
       x = model_matrix_X_train, 
       y = matrix_Y_train,
       alpha = 0,
       family = "binomial",
       type.measure = "auc",
       nfolds = 10)

breast_cancer_cv_lambda_ridge 
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'c3a4d04138f12420be1540d11aa0916f', 'grade': True, 'grade_id': 'cell-835f590ffa33093d', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.1()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "815530e6c9619757bbdde75b9b8109c1", "grade": false, "grade_id": "cell-66e037cf38a28c2e", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.2**

The object `breast_cancer_cv_lambda_ridge` from `cv.glmnet()` is a list of different elements. We find the optimum value for $\lambda$ in ridge regression with this object. We can use `breast_cancer_cv_lambda_ridge` via `plot()` to visualize the resulting cross-validation AUCs for each value of $\lambda$. Recall that there are $k$ AUC values for each $\lambda$.

The resulting plot will indicate the average AUC (red dot) and error bars (in grey) on the $y$-axis along with the $\lambda$ sequence on the $x$-axis in log-scale. 


The top $x$-axis will indicate the number of inputs whose estimated coefficients are different from zero by each value of $\lambda$. Note that for Ridge we will always see the to on this top $x$-axis since the Ridge penalty never shrinks estimates to zero. 

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '954f22a41c9e0ba75f14a90f99100421', 'grade': False, 'grade_id': 'cell-c2a4f5f034b93c5e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Adjust these numbers so the plot looks good in your computer.
options(repr.plot.width = 16, repr.plot.height = 8) 

# plot(..., 
#      main = "Cross-Validation with Ridge Regression\n\n")

# your code here
plot(breast_cancer_cv_lambda_ridge, 
     main = "Cross-Validation with Ridge Regression\n\n")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "75c134546ebf5538afb426126e2dddf3", "grade": false, "grade_id": "cell-e261694b0682df04", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.3**
<br>{points: 1}

The plot in **Question 1.2** shows two vertical dotted lines. *Given an `object` coming from `cv.glmnet()`*, these lines correspond to two values of $\lambda$:

- $\hat{\lambda}_{\text{min}}$ which provides the maximum average AUC out of the whole sequence for $\lambda$. We can obtain it with `object$lambda.min`.


- $\hat{\lambda}_{\text{1SE}}$ the highest $\lambda$ for which average AUC within one standard error of the maximum. We can obtain it with `object$lambda.1se`.


Using `breast_cancer_cv_lambda_ridge`, obtain $\hat{\lambda}_{\text{min}}$ and assign it to the variable `breast_cancer_lambda_max_AUC_ridge`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '475f40c0a3b68a7bb3432c2c685db42b', 'grade': False, 'grade_id': 'cell-a021fb07ef950e15', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# breast_cancer_lambda_max_AUC_ridge <- round(..., 4)


# your code here
breast_cancer_lambda_max_AUC_ridge <- round(breast_cancer_cv_lambda_ridge$lambda.min, 4)

breast_cancer_lambda_max_AUC_ridge
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b432bd1505ca3a4814b059ef43b37436', 'grade': True, 'grade_id': 'cell-614151328ec24c6b', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.3()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "a9fefd2b524f995d32d16ab5e4c38610", "grade": false, "grade_id": "cell-04b486fbda1e80ec", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.4**

Visualize the estimated regression coefficients all over the $\lambda$ range. 

Use `breast_cancer_cv_lambda_ridge$glmnet.fit` along with a second argument called `"lambda"` within the function `plot()`. 

You will see that the estimated coefficients shrink towards zero as the value of $\lambda$ increases. Moreover, use the `abline()` function to indicate `breast_cancer_lambda_max_AUC_ridge` as a vertical dashed line in red **on the natural logarithm scale**.


*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '52d0769697d3cca6c8ec50f3ceed5299', 'grade': False, 'grade_id': 'cell-c6b6e6ef693202a4', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# ...(..., "lambda")
# ...(v = ..., col = "red", lwd = 3, lty = 2)

# your code here
plot(breast_cancer_cv_lambda_ridge$glmnet.fit, "lambda")
abline(v = breast_cancer_lambda_max_AUC_ridge, col = "red", lwd = 3, lty = 2)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "8cd7c35200b232fd341df01be6f6f18d", "grade": false, "grade_id": "cell-adc160d84caf9fb4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.5**
<br>{points: 1}

Once we have the optimum value for $\lambda$, let us fit the ridge regression model we will compare versus `breast_cancer_logistic_model` (from the worksheet). We will use the function `glmnet()` along with `model_matrix_X_train` and `matrix_Y_train`. Extract the fit for a `lambda` value equal to `breast_cancer_lambda_max_AUC_ridge`.

Call the resulting estimated model `breast_cancer_ridge_max_AUC`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'd01c0be737d60247b5c5f0cb0f130d58', 'grade': False, 'grade_id': 'cell-68173370a9412726', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(1234) # DO NOT CHANGE!

# breast_cancer_ridge_max_AUC <- 
#   glmnet(
#   x = ..., y = ...,
#   alpha = ...,
#   family = ...,
#   lambda = ...
# )

#coef(breast_cancer_ridge_max_AUC)

# your code here
breast_cancer_ridge_max_AUC <- 
  glmnet(
  x = model_matrix_X_train, y = matrix_Y_train,
  alpha = 0,
  family = "binomial",
  lambda = breast_cancer_lambda_max_AUC_ridge
)

coef(breast_cancer_ridge_max_AUC)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1710099f5e8e8f6723b4f94e6e6b919a', 'grade': True, 'grade_id': 'cell-2c0eb422bcc9a64c', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.5()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "ea96b117ec659b02738d4111aa6b6fb4", "grade": false, "grade_id": "cell-30eea616995e9e66", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**CV-AUC for a Logistic Regression (without penalization)**

In `worksheet_13`, we've computed the CV missclassification error for a classical (non-penalized) logistic regression. Let's compute here the CV AUC to compare it with that of  penalized models. Read the given code if you want to learn more about CV!

*Run the following cell.*
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '93daebea195b333013762537d7dd2f4d', 'grade': False, 'grade_id': 'cell-f4f34fffcbe4e5db', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
set.seed(1234)
num.folds <- 10

folds <- createFolds(breast_cancer_train$target, k=num.folds)

regr.cv <- NULL
for (fold in 1:num.folds) {
train.idx <- setdiff(1:nrow(breast_cancer_train), folds[[fold]])
regr.cv[[fold]] <- glm(target ~ ., data=breast_cancer_train, subset=train.idx,
                       family="binomial")
    }

pred.cv <- NULL
auc.cv <- numeric(num.folds) 

for (fold in 1:num.folds) {
test.idx <- folds[[fold]]
pred.cv[[fold]] <- data.frame(obs=breast_cancer_train$target[test.idx],
pred=predict(regr.cv[[fold]], newdata=breast_cancer_train, type="response")[test.idx])
auc.cv[fold] <- roc(obs ~ pred, data=pred.cv[[fold]])$auc
    }

breast_cancer_cv_ordinary <- round(mean(auc.cv),7)

cat("Cross-validation AUC for the ordinary logistic model:", 
breast_cancer_cv_ordinary)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "96f1d530943f5bf918981bc778386938", "grade": false, "grade_id": "cell-e17a6bb188ec831d", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.6**
<br>{points: 1}

To help us keep track of the AUC for different models, let's create a data frame with the AUC computed by CV for each of our models: (1) ridge logistic regression and (2) ordinary logistic regression (from the worksheet). 

Note that all the average AUC values from the CV are stored in an object called `cvm` from  `cv.glmnet`. 

Store the ridge and ordinary models' cross-validation AUCs in a tibble called `breast_cancer_AUC_models` with two columns:

- `model`: The regression model from which we will obtain the prediction accuracy. This will be a string vector with elements: `"ordinary"` and `"ridge"`.
- `auc`: A numerical vector with AUC corresponding to each model.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5449a40a649deb43e6e873549d057a9f', 'grade': False, 'grade_id': 'cell-f0afa561df6d811e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# breast_cancer_AUC_models <- 
#     tibble(
#         model = ...,
#         auc = ...)

# breast_cancer_AUC_models

# your code here
breast_cancer_AUC_models <- 
    tibble(
        model = c("ordinary", "ridge"),
        auc = c(breast_cancer_cv_ordinary, breast_cancer_cv_lambda_ridge$cvm[breast_cancer_cv_lambda_ridge$index[1]]))

breast_cancer_AUC_models
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '27d9e3d1e102e11f0d45a079ebe99fd2', 'grade': True, 'grade_id': 'cell-e5db713d17d45704', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.6()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "3fce31879cd0c21cb914e23723fb58f9", "grade": false, "grade_id": "cell-2c2c92a01d9b879e", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## LASSO Regression
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "418fe6010b6038e9c3a3136397d035b1", "grade": false, "grade_id": "cell-7f013a0c81ea6a07", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.7**
<br>{points: 1}

We already prepared our training data with `model_matrix_X_train` and `matrix_Y_train`. Now we need to find the value of $\lambda$ in $L_{\text{LASSO}}(\beta_0, \beta_1, \dots, \beta_{p-1})$ that provides the largest average AUC. 

Use the function `cv.glmnet()`. Remember LASSO regression is defined when `alpha` is equal to one.  Specify the proper accuracy `type.measure` and number of folds `nfolds` (use $k = 5$) along with the correct argument for `family`.

*Assign the function's output as `breast_cancer_cv_lambda_LASSO`.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'cb6686ed4f95ed0a7212b06f1f84280b', 'grade': False, 'grade_id': 'cell-883249cf69a785fb', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(1234) # do not change this!

# breast_cancer_cv_lambda_LASSO <- 
#   ...(
#   x = ..., y = ...,
#   alpha = ...,
#   family = ...,
#   type.measure = ...,
#   nfolds = ...)

# breast_cancer_cv_lambda_LASSO

# your code here
breast_cancer_cv_lambda_LASSO <- 
  cv.glmnet(
  x = model_matrix_X_train, y = matrix_Y_train,
  alpha = 1,
  family = "binomial",
  type.measure = "auc",
  nfolds = 5)

breast_cancer_cv_lambda_LASSO
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'f6045dec6e696c21c112d29b0852f9fa', 'grade': True, 'grade_id': 'cell-91d3a9c9fc9e7363', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.7()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "0db5b40da7920d8c0be52eefd8aec03c", "grade": false, "grade_id": "cell-011a6ef73a2f1466", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
The object `breast_cancer_cv_lambda_LASSO` is also a list of different elements we will use to obtain the LASSO regression with an optimum value for $\lambda$. As before, we can use the function `plot()` to visualize the cross-validation AUC values for each value of the $\lambda$ sequence.

This time, for LASSO logistic regression, we will see different values on this top $x$-axis since the model will shrink some coefficients to exactly zero. 

The following plot compares the Ridge and the LASSO path to select lambda values. You can see that for LASSO, but not for Ridge, all estimates will become zero for large $\lambda$ values.

*Run the cell below.*
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'c5e49d30f24eefdcfa48f4b57ccd0bc5', 'grade': False, 'grade_id': 'cell-d4bcba2f51bcac63', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
options(repr.plot.width = 16, repr.plot.height = 8) # Adjust these numbers so the plot looks good in your desktop.

plot(breast_cancer_cv_lambda_ridge, main = "Cross-Validation with Ridge Regression\n\n")

plot(breast_cancer_cv_lambda_LASSO, main = "Cross-Validation with LASSO\n\n")
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "97088f2d82d22bfd8998f96862af1f3f", "grade": false, "grade_id": "cell-9b5b297a5b489184", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.8**
<br>{points: 1}

The plot of the output coming from `cv.glmnet()` shows two vertical dotted lines. These lines correspond to two values of $\lambda$:

- $\hat{\lambda}_{\text{min}}$ which provides the maximum average AUC out of the whole sequence for $\lambda$. We can obtain it with `object$lambda.min`.


- $\hat{\lambda}_{\text{1SE}}$ is the highest $\lambda$ for which the model has an average AUC within one standard error of the maximum. We can obtain it with `object$lambda.1se`.


In some cases, $\hat{\lambda}_{\text{1SE}}$ is preferable because we can select a considerably simpler model (three variables instead of seven) without having a significant reduction of the AUC. 

Using `breast_cancer_cv_lambda_LASSO`, obtain $\hat{\lambda}_{\text{1se}}$ and assign it to the variable `breast_cancer_lambda_1se_AUC_LASSO`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b924a16bed491ef4ff03e6c1c092f741', 'grade': False, 'grade_id': 'cell-4662013411dcd6c7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# breast_cancer_lambda_1se_AUC_LASSO <- round(..., 4)

# your code here
breast_cancer_lambda_1se_AUC_LASSO <- round(breast_cancer_cv_lambda_LASSO$lambda.1se, 4)

breast_cancer_lambda_1se_AUC_LASSO
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '0acfec2462af0c6c19dd654d1b2b967d', 'grade': True, 'grade_id': 'cell-ed8ce5eab9b63eca', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.8()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "767ce5b772c8c3daa9d071a579972ec3", "grade": false, "grade_id": "cell-5da6f59490c656c8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.9**
<br>{points: 1}

Let's compare the LASSO logistic model fit at the `lambda.1se` with `breast_cancer_log_model` and `breast_cancer_ridge_max_AUC`. 

We will use the function `glmnet()` along with `breast_cancer_X_train` and `breast_cancer_Y_train`. Extract the estimated model for `lambda` equal to `breast_cancer_lambda_1se_AUC_LASSO`. Call the output `breast_cancer_LASSO_1se_AUC`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '1b6106058bd933706a9efa57b4704c95', 'grade': False, 'grade_id': 'cell-bc8ffa02973dbe07', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
set.seed(1234) # do not change this!

# breast_cancer_LASSO_1se_AUC <- ...(
#   x = ..., y = ...,
#   alpha = ...,
#   family = ...,
#   lambda = ...
# )

# breast_cancer_LASSO_1se_AUC

# your code here
breast_cancer_LASSO_1se_AUC <- glmnet(
  x = model_matrix_X_train, y = matrix_Y_train,
  alpha = 1,
  family = "binomial",
  lambda = breast_cancer_lambda_1se_AUC_LASSO
)

coef(breast_cancer_LASSO_1se_AUC)
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '96142473ba1749841f99d96a48b3978c', 'grade': True, 'grade_id': 'cell-eac7fb7a73a1ecbe', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.9()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "c273628101a7546582767996218e9847", "grade": false, "grade_id": "cell-0a3de48f0069fc4e", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.10**
<br>{points: 1}


Based on the results above, where those estimated regression coefficients equal to zero are shown as `.`, what input variables are selected in `breast_cancer_LASSO_1se_AUC`?

**A.** `mean_radius`.

**B.** `mean_texture`.

**C.** `mean_perimeter`.

**D.** `mean_smoothness`.

**E.** `mean_compactness`.

**F.** `mean_concavity`.

**G.** `mean_concave_points`.

**H.** `mean_symmetry`.

**I.** `mean_fractal_dimension`.

**J.** `radius_error`.

**K.** `texture_error`.

**L.** `perimeter_error`.

**M.** `smoothness_error`.

**N.** `compactness_error`.

**O.** `symmetry_error`.

**P.** `fractal_dimension_error`.

*Assign your answers to the object `answer1.12`. Your answers have to be included in a single string indicating the correct options **in alphabetical order** and surrounded by quotes.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5f2c044a968eee5f2d664b7819886fe3', 'grade': False, 'grade_id': 'cell-88d1ffea05d9a704', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.10 <- 

# your code here
answer1.10 <- "BCG"
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'e195b6681073af810c86ecb5e6a4f889', 'grade': True, 'grade_id': 'cell-24ac1044844b4537', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.10()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "103daca282c0614021e36aa8d5bfe3fe", "grade": false, "grade_id": "cell-85cb8a8afe9290d7", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.11**
<br>{points: 1}

Let's add the Lasso Logistic Regression row to our `breast_cancer_AUC_models` tibble. 

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '173e8338cba7f5a356386058eec2aaf8', 'grade': False, 'grade_id': 'cell-ebbdef6a9bbd97ec', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# breast_cancer_AUC_models <- 
#     breast_cancer_AUC_models %>% 
#     add_row(model = ..., 
#             auc = ...)

# your code here
breast_cancer_AUC_models <- 
    breast_cancer_AUC_models %>% 
    add_row(model = "Lasso Logistic Regression", 
            auc = breast_cancer_cv_lambda_LASSO$cvm[20])

breast_cancer_AUC_models
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '2698a5fa352a70374627ccf18f78990f', 'grade': True, 'grade_id': 'cell-caced323bccdd520', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.11()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "d5f910d5f07b33bdeba0383e23f3eb89", "grade": false, "grade_id": "cell-7d6d7e68aee6ee87", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
Great job! You can now choose a model that you expect will have a good prediction performance based on the CV results, without looking at the test set!! 

We can see that the ridge model is slightly better, although we used the $\lambda_{\min}$ for ridge and $\lambda_{1se}$ for lasso. On the other hand, the model selected by LASSO is considerably simpler since it uses only three of the variables while keeping similar performance. 

After choosing the model, you can apply the chosen model to the test set to estimate the model's performance. 
<!-- #endregion -->

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "331905cc71be9396edca6028955686bd", "grade": false, "grade_id": "cell-721dc2524874e319", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.12**
<br>{points: 1}

Suppose you chose the LASSO model. Use the model to predict the `target` variable on the **test** set (`breast_cancer_test`). Then, use the `roc` function to obtain the ROC curve in the test set. Save the result in an object named ROC_LASSO. 


*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': 'b5845f6bd96266d8e16fed56faedc6df', 'grade': False, 'grade_id': 'cell-a72d2162ab0d59ef', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# model_matrix_X_test <- 
#     ...(object = ...,
#                  data = ....)[, -1]

# ROC_lasso <- 
#     roc(
#         response = ...,
#         predictor = predict(...,
#                      newx = ...)[,"s0"] ) 

# your code here
model_matrix_X_test <- 
    model.matrix(object = target ~ .,
                 data = breast_cancer_test)[, -1]

ROC_lasso <- 
    roc(
        response = breast_cancer_test$target,
        predictor = predict(breast_cancer_LASSO_1se_AUC,
                     newx = model_matrix_X_test)[,"s0"] ) 

ROC_lasso
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '78deddf9fd5da63f073a280dd167dfd4', 'grade': True, 'grade_id': 'cell-aadb329e2f98cbfc', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.12()
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "cb3a176d30b3a0650ec05634c3e6f597", "grade": false, "grade_id": "cell-138a75b77a426c32", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
We can use the `plot` function to plot the `ROC_lasso` curve from the Lasso model in the test set. 

*Run the cell below.*
<!-- #endregion -->

```{r deletable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '5e067732a3fc601b91958ff9e39e02cb', 'grade': False, 'grade_id': 'cell-e681613eba1a7b5b', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# your code here
plot(ROC_lasso)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "24faeb75f57a9d633f758883a6ff5c14", "grade": false, "grade_id": "cell-d286bfc8f2e59df1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
Out of curiosity, let's check how the other two models perform in the test set. 
<!-- #endregion -->

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '164cea931cab1c208c7bc47e529f1065', 'grade': False, 'grade_id': 'cell-ef1802fce5c5970b', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing

ROC_ridge <- roc(
  response = breast_cancer_test$target,
  predictor = predict(breast_cancer_ridge_max_AUC,
                      newx = model_matrix_X_test )[,"s0"] )

ROC_ordinary <- roc(
  response = breast_cancer_test$target,
  predictor = predict(breast_cancer_logistic_model,
                      newdata = breast_cancer_test) )
```

```{r deletable=FALSE, editable=FALSE, nbgrader={'cell_type': 'code', 'checksum': '0e685496238619fd144bfa441a3aeee9', 'grade': False, 'grade_id': 'cell-e40fd879f8744cc0', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
plot(ROC_lasso,
  print.auc = TRUE, col = "blue", lwd = 3, lty = 2,
  main = "ROC Curves for Breast Cancer Dataset"
)

lines.roc(ROC_ridge, col = "green", lwd = 3, lty = 2, print.auc=TRUE)
lines.roc(ROC_ordinary, col = "red", lwd = 3, lty = 2)
```

<!-- #region deletable=false editable=false nbgrader={"cell_type": "markdown", "checksum": "b2e8b725e42ebd3d14b6cfcead1e232b", "grade": false, "grade_id": "cell-00d211376f84ead1", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
From the ROC curve in the test set, the LASSO model performs worse (although reasonably close) to the other two models. So you might be tempted to switch models at this point. But changing models at this stage will bring optimization bias again, making the estimates of AUC obtained here to overestimate the AUC in (new) unseen data. 
<!-- #endregion -->

```{r}

```
